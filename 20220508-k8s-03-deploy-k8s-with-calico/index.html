

<!DOCTYPE html>
<html lang="en" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="https://resource.tinychen.com/logos.png">
  <link rel="icon" href="https://resource.tinychen.com/logos.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
    <meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="TinyChen">
  <meta name="keywords" content="">
  
    <meta name="description" content="本文主要在centos7系统上基于docker和calico组件部署v1.23.6版本的k8s原生集群，由于集群主要用于自己平时学习和测试使用，加上资源有限，暂不涉及高可用部署。 此前写的一些关于k8s基础知识和集群搭建的一些方案，有需要的同学可以看一下。">
<meta property="og:type" content="article">
<meta property="og:title" content="k8s系列03-kubeadm部署calico网络的k8s集群">
<meta property="og:url" content="https://tinychen.com/20220508-k8s-03-deploy-k8s-with-calico/index.html">
<meta property="og:site_name" content="TinyChen&#39;s Studio - 互联网技术学习工作经验分享">
<meta property="og:description" content="本文主要在centos7系统上基于docker和calico组件部署v1.23.6版本的k8s原生集群，由于集群主要用于自己平时学习和测试使用，加上资源有限，暂不涉及高可用部署。 此前写的一些关于k8s基础知识和集群搭建的一些方案，有需要的同学可以看一下。">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://resource.tinychen.com/202205071958328.jpg">
<meta property="article:published_time" content="2022-05-08T05:00:00.000Z">
<meta property="article:modified_time" content="2022-05-08T05:00:00.000Z">
<meta property="article:author" content="TinyChen">
<meta property="article:tag" content="centos">
<meta property="article:tag" content="k8s">
<meta property="article:tag" content="docker">
<meta property="article:tag" content="calico">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://resource.tinychen.com/202205071958328.jpg">
  
  
  <title>k8s系列03-kubeadm部署calico网络的k8s集群 - TinyChen&#39;s Studio - 互联网技术学习工作经验分享</title>

  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4/github-markdown.min.css" />
  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hint.css@2/hint.min.css" />

  
    
    
      
      <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@10/styles/dracula.min.css" />
    
  

  
    <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3/dist/jquery.fancybox.min.css" />
  


<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->

  
<link rel="stylesheet" href="/css/fluid-extention.css">



  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    var CONFIG = {"hostname":"tinychen.com","root":"/","version":"1.8.14","typing":{"enable":true,"typeSpeed":30,"cursorChar":"_","loop":false},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"right","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"copy_btn":true,"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"baidu":"7a96963a1145ac7fde1442d739a11ffd","google":"UA-166769908-1","gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
<meta name="generator" content="Hexo 5.4.2"><link rel="alternate" href="/atom.xml" title="TinyChen's Studio - 互联网技术学习工作经验分享" type="application/atom+xml">
</head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>TinyChen</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                Home
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                Archives
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                Categories
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                Tags
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                About
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="banner" id="banner" parallax=true
         style="background: url('https://resource.tinychen.com/202205071959526.jpg') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="page-header text-center fade-in-up">
            <span class="h2" id="subtitle" title="k8s系列03-kubeadm部署calico网络的k8s集群">
              
            </span>

            
              <div class="mt-3">
  
  
    <span class="post-meta">
      <i class="iconfont icon-date-fill" aria-hidden="true"></i>
      <time datetime="2022-05-08 13:00" pubdate>
        May 8, 2022 pm
      </time>
    </span>
  
</div>

<div class="mt-1">
  
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      33k 字
    </span>
  

  

  
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div class="py-5" id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">k8s系列03-kubeadm部署calico网络的k8s集群</h1>
            
              <p class="note note-info">
                
                  本文最后更新于：May 8, 2022 pm
                
              </p>
            
            <div class="markdown-body">
              <p>本文主要在centos7系统上基于<code>docker</code>和<code>calico</code>组件部署<code>v1.23.6</code>版本的k8s原生集群，由于集群主要用于自己平时学习和测试使用，加上资源有限，暂不涉及高可用部署。</p>
<p>此前写的一些关于k8s基础知识和集群搭建的一些<a href="https://tinychen.com/tags/k8s/">方案</a>，有需要的同学可以看一下。</p>
<span id="more"></span>

<h1 id="1、准备工作"><a href="#1、准备工作" class="headerlink" title="1、准备工作"></a>1、准备工作</h1><h2 id="1-1-calico-集群节点信息"><a href="#1-1-calico-集群节点信息" class="headerlink" title="1.1 calico-集群节点信息"></a>1.1 calico-集群节点信息</h2><p>机器均为8C8G的虚拟机，硬盘为100G。</p>
<table>
<thead>
<tr>
<th align="center">IP</th>
<th align="center">Hostname</th>
</tr>
</thead>
<tbody><tr>
<td align="center">10.31.88.1</td>
<td align="center">tiny-calico-master-88-1.k8s.tcinternal</td>
</tr>
<tr>
<td align="center">10.31.88.11</td>
<td align="center">tiny-calico-worker-88-11.k8s.tcinternal</td>
</tr>
<tr>
<td align="center">10.31.88.12</td>
<td align="center">tiny-calico-worker-88-12.k8s.tcinternal</td>
</tr>
<tr>
<td align="center">10.88.64.0&#x2F;18</td>
<td align="center">podSubnet</td>
</tr>
<tr>
<td align="center">10.88.0.0&#x2F;18</td>
<td align="center">serviceSubnet</td>
</tr>
</tbody></table>
<h2 id="1-2-检查mac和product-uuid"><a href="#1-2-检查mac和product-uuid" class="headerlink" title="1.2 检查mac和product_uuid"></a>1.2 检查mac和product_uuid</h2><p>同一个k8s集群内的所有节点需要确保<code>mac</code>地址和<code>product_uuid</code>均唯一，开始集群初始化之前需要检查相关信息</p>
<figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash"><span class="hljs-comment"># 检查mac地址</span><br>ip <span class="hljs-built_in">link</span> <br>ifconfig -a<br><br><span class="hljs-comment"># 检查product_uuid</span><br>sudo <span class="hljs-built_in">cat</span> /sys/class/dmi/id/product_uuid<br></code></pre></div></td></tr></table></figure>



<h2 id="1-3-配置ssh免密登录（可选）"><a href="#1-3-配置ssh免密登录（可选）" class="headerlink" title="1.3 配置ssh免密登录（可选）"></a>1.3 配置ssh免密登录（可选）</h2><p>如果k8s集群的节点有多个网卡，确保每个节点能通过正确的网卡互联访问</p>
<figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash"><span class="hljs-comment"># 在root用户下面生成一个公用的key，并配置可以使用该key免密登录</span><br>su root<br>ssh-keygen<br><span class="hljs-built_in">cd</span> /root/.ssh/<br><span class="hljs-built_in">cat</span> id_rsa.pub &gt;&gt; authorized_keys<br><span class="hljs-built_in">chmod</span> 600 authorized_keys<br><br><br><span class="hljs-built_in">cat</span> &gt;&gt; ~/.ssh/config &lt;&lt;<span class="hljs-string">EOF</span><br><span class="hljs-string">Host tiny-calico-master-88-1.k8s.tcinternal</span><br><span class="hljs-string">    HostName 10.31.88.1</span><br><span class="hljs-string">    User root</span><br><span class="hljs-string">    Port 22</span><br><span class="hljs-string">    IdentityFile ~/.ssh/id_rsa</span><br><span class="hljs-string"></span><br><span class="hljs-string">Host tiny-calico-worker-88-11.k8s.tcinternal</span><br><span class="hljs-string">    HostName 10.31.88.11</span><br><span class="hljs-string">    User root</span><br><span class="hljs-string">    Port 22</span><br><span class="hljs-string">    IdentityFile ~/.ssh/id_rsa</span><br><span class="hljs-string"></span><br><span class="hljs-string">Host tiny-calico-worker-88-12.k8s.tcinternal</span><br><span class="hljs-string">    HostName 10.31.88.12</span><br><span class="hljs-string">    User root</span><br><span class="hljs-string">    Port 22</span><br><span class="hljs-string">    IdentityFile ~/.ssh/id_rsa</span><br><span class="hljs-string">EOF</span><br></code></pre></div></td></tr></table></figure>



<h2 id="1-4-修改hosts文件"><a href="#1-4-修改hosts文件" class="headerlink" title="1.4 修改hosts文件"></a>1.4 修改hosts文件</h2><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash"><span class="hljs-built_in">cat</span> &gt;&gt; /etc/hosts &lt;&lt;<span class="hljs-string">EOF</span><br><span class="hljs-string">10.31.88.1  tiny-calico-master-88-1 tiny-calico-master-88-1.k8s.tcinternal</span><br><span class="hljs-string">10.31.88.11 tiny-calico-worker-88-11 tiny-calico-worker-88-11.k8s.tcinternal</span><br><span class="hljs-string">10.31.88.12 tiny-calico-worker-88-12 tiny-calico-worker-88-12.k8s.tcinternal</span><br><span class="hljs-string">EOF</span><br></code></pre></div></td></tr></table></figure>



<h2 id="1-5-关闭swap内存"><a href="#1-5-关闭swap内存" class="headerlink" title="1.5 关闭swap内存"></a>1.5 关闭swap内存</h2><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash"><span class="hljs-comment"># 使用命令直接关闭swap内存</span><br>swapoff -a<br><span class="hljs-comment"># 修改fstab文件禁止开机自动挂载swap分区</span><br>sed -i <span class="hljs-string">&#x27;/swap / s/^\(.*\)$/#\1/g&#x27;</span> /etc/fstab<br></code></pre></div></td></tr></table></figure>



<h2 id="1-6-配置时间同步"><a href="#1-6-配置时间同步" class="headerlink" title="1.6 配置时间同步"></a>1.6 配置时间同步</h2><p>这里可以根据自己的习惯选择ntp或者是chrony同步均可，同步的时间源服务器可以选择阿里云的<code>ntp1.aliyun.com</code>或者是国家时间中心的<code>ntp.ntsc.ac.cn</code>。</p>
<h3 id="使用ntp同步"><a href="#使用ntp同步" class="headerlink" title="使用ntp同步"></a>使用ntp同步</h3><figure class="highlight cmake"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs cmake"><span class="hljs-comment"># 使用yum安装ntpdate工具</span><br>yum <span class="hljs-keyword">install</span> ntpdate -y<br><br><span class="hljs-comment"># 使用国家时间中心的源同步时间</span><br>ntpdate ntp.ntsc.ac.cn<br><br><span class="hljs-comment"># 最后查看一下时间</span><br>hwclock<br></code></pre></div></td></tr></table></figure>

<h3 id="使用chrony同步"><a href="#使用chrony同步" class="headerlink" title="使用chrony同步"></a>使用chrony同步</h3><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash"><span class="hljs-comment"># 使用yum安装chrony</span><br>yum install chrony -y<br><br><span class="hljs-comment"># 设置开机启动并开启chony并查看运行状态</span><br>systemctl <span class="hljs-built_in">enable</span> chronyd.service<br>systemctl start chronyd.service<br>systemctl status chronyd.service<br><br><span class="hljs-comment"># 当然也可以自定义时间服务器</span><br>vim /etc/chrony.conf<br><br><span class="hljs-comment"># 修改前</span><br>$ grep server /etc/chrony.conf<br><span class="hljs-comment"># Use public servers from the pool.ntp.org project.</span><br>server 0.centos.pool.ntp.org iburst<br>server 1.centos.pool.ntp.org iburst<br>server 2.centos.pool.ntp.org iburst<br>server 3.centos.pool.ntp.org iburst<br><br><span class="hljs-comment"># 修改后</span><br>$ grep server /etc/chrony.conf<br><span class="hljs-comment"># Use public servers from the pool.ntp.org project.</span><br>server ntp.ntsc.ac.cn iburst<br><br><span class="hljs-comment"># 重启服务使配置文件生效</span><br>systemctl restart chronyd.service<br><br><span class="hljs-comment"># 查看chrony的ntp服务器状态</span><br>chronyc sourcestats -v<br>chronyc sources -v<br><br></code></pre></div></td></tr></table></figure>



<h2 id="1-7-关闭selinux"><a href="#1-7-关闭selinux" class="headerlink" title="1.7 关闭selinux"></a>1.7 关闭selinux</h2><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash"><span class="hljs-comment"># 使用命令直接关闭</span><br>setenforce 0<br><br><span class="hljs-comment"># 也可以直接修改/etc/selinux/config文件</span><br>sed -i <span class="hljs-string">&#x27;s/^SELINUX=enforcing$/SELINUX=disabled/&#x27;</span> /etc/selinux/config<br></code></pre></div></td></tr></table></figure>



<h2 id="1-8-配置防火墙"><a href="#1-8-配置防火墙" class="headerlink" title="1.8 配置防火墙"></a>1.8 配置防火墙</h2><p>k8s集群之间通信和服务暴露需要使用较多端口，为了方便，直接禁用防火墙</p>
<figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash"><span class="hljs-comment"># centos7使用systemctl禁用默认的firewalld服务</span><br>systemctl <span class="hljs-built_in">disable</span> firewalld.service<br></code></pre></div></td></tr></table></figure>



<h2 id="1-9-配置netfilter参数"><a href="#1-9-配置netfilter参数" class="headerlink" title="1.9 配置netfilter参数"></a>1.9 配置netfilter参数</h2><p>这里主要是需要配置内核加载<code>br_netfilter</code>和<code>iptables</code>放行<code>ipv6</code>和<code>ipv4</code>的流量，确保集群内的容器能够正常通信。</p>
<figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash"><span class="hljs-built_in">cat</span> &lt;&lt;<span class="hljs-string">EOF | sudo tee /etc/modules-load.d/k8s.conf</span><br><span class="hljs-string">br_netfilter</span><br><span class="hljs-string">EOF</span><br><br><span class="hljs-built_in">cat</span> &lt;&lt;<span class="hljs-string">EOF | sudo tee /etc/sysctl.d/k8s.conf</span><br><span class="hljs-string">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="hljs-string">net.bridge.bridge-nf-call-iptables = 1</span><br><span class="hljs-string">EOF</span><br>sudo sysctl --system<br></code></pre></div></td></tr></table></figure>



<h2 id="1-10-关闭IPV6（可选）"><a href="#1-10-关闭IPV6（可选）" class="headerlink" title="1.10 关闭IPV6（可选）"></a>1.10 关闭IPV6（可选）</h2><p>虽然新版本的k8s已经支持双栈网络，但是本次的集群部署过程并不涉及IPv6网络的通信，因此关闭IPv6网络支持</p>
<figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash"><span class="hljs-comment"># 直接在内核中添加ipv6禁用参数</span><br>grubby --update-kernel=ALL --args=ipv6.disable=1<br></code></pre></div></td></tr></table></figure>

<h2 id="1-11-配置IPVS（可选）"><a href="#1-11-配置IPVS（可选）" class="headerlink" title="1.11 配置IPVS（可选）"></a>1.11 配置IPVS（可选）</h2><p>IPVS是专门设计用来应对负载均衡场景的组件，<a target="_blank" rel="noopener" href="https://github.com/kubernetes/kubernetes/blob/master/pkg/proxy/ipvs/README.md#run-kube-proxy-in-ipvs-mode">kube-proxy 中的 IPVS 实现</a>通过减少对 iptables 的使用来增加可扩展性。在 iptables 输入链中不使用 PREROUTING，而是创建一个假的接口，叫做 kube-ipvs0，当k8s集群中的负载均衡配置变多的时候，IPVS能实现比iptables更高效的转发性能。</p>
<blockquote>
<p>注意在4.19之后的内核版本中使用<code>nf_conntrack</code>模块来替换了原有的<code>nf_conntrack_ipv4</code>模块</p>
<p>(<strong>Notes</strong>: use <code>nf_conntrack</code> instead of <code>nf_conntrack_ipv4</code> for Linux kernel 4.19 and later)</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash"><span class="hljs-comment"># 在使用ipvs模式之前确保安装了ipset和ipvsadm</span><br>sudo yum install ipset ipvsadm -y<br><br><span class="hljs-comment"># 手动加载ipvs相关模块</span><br>modprobe -- ip_vs<br>modprobe -- ip_vs_rr<br>modprobe -- ip_vs_wrr<br>modprobe -- ip_vs_sh<br>modprobe -- nf_conntrack_ipv4<br><br><span class="hljs-comment"># 配置开机自动加载ipvs相关模块</span><br><span class="hljs-built_in">cat</span> &lt;&lt;<span class="hljs-string">EOF | sudo tee /etc/modules-load.d/ipvs.conf</span><br><span class="hljs-string">ip_vs</span><br><span class="hljs-string">ip_vs_rr</span><br><span class="hljs-string">ip_vs_wrr</span><br><span class="hljs-string">ip_vs_sh</span><br><span class="hljs-string">nf_conntrack_ipv4</span><br><span class="hljs-string">EOF</span><br><br>sudo sysctl --system<br><span class="hljs-comment"># 最好重启一遍系统确定是否生效</span><br><br>$ lsmod | grep -e ip_vs -e nf_conntrack_ipv4<br>ip_vs_sh               12688  0<br>ip_vs_wrr              12697  0<br>ip_vs_rr               12600  0<br>ip_vs                 145458  6 ip_vs_rr,ip_vs_sh,ip_vs_wrr<br>nf_conntrack_ipv4      15053  2<br>nf_defrag_ipv4         12729  1 nf_conntrack_ipv4<br>nf_conntrack          139264  7 ip_vs,nf_nat,nf_nat_ipv4,xt_conntrack,nf_nat_masquerade_ipv4,nf_conntrack_netlink,nf_conntrack_ipv4<br>libcrc32c              12644  4 xfs,ip_vs,nf_nat,nf_conntrack<br>$ <span class="hljs-built_in">cut</span> -f1 -d <span class="hljs-string">&quot; &quot;</span>  /proc/modules | grep -e ip_vs -e nf_conntrack_ipv4<br>ip_vs_sh<br>ip_vs_wrr<br>ip_vs_rr<br>ip_vs<br>nf_conntrack_ipv4<br></code></pre></div></td></tr></table></figure>



<h1 id="2、安装container-runtime"><a href="#2、安装container-runtime" class="headerlink" title="2、安装container runtime"></a>2、安装container runtime</h1><h2 id="2-1-安装docker"><a href="#2-1-安装docker" class="headerlink" title="2.1 安装docker"></a>2.1 安装docker</h2><p>详细的官方文档可以参考<a target="_blank" rel="noopener" href="https://kubernetes.io/docs/setup/production-environment/container-runtimes/">这里</a>，由于在刚发布的1.24版本中移除了<code>docker-shim</code>，因此安装的<code>版本≥1.24</code>的时候需要注意<code>容器运行时</code>的选择。这里我们安装的版本低于1.24，因此我们继续使用docker。</p>
<p>docker的具体安装可以参考我之前写的<a href="https://tinychen.com/20190912-centos-install-docker/">这篇文章</a>，这里不做赘述。</p>
<figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash"><span class="hljs-comment"># 安装必要的依赖组件并且导入docker官方提供的yum源</span><br>sudo yum install -y yum-utils device-mapper-persistent-data lvm2<br>sudo yum-config-manager --add-repo  https://download.docker.com/linux/centos/docker-ce.repo<br><br><span class="hljs-comment"># 我们直接安装最新版本的docker</span><br>yum install docker-ce docker-ce-cli containerd.io<br></code></pre></div></td></tr></table></figure>

<h2 id="2-2-配置cgroup-drivers"><a href="#2-2-配置cgroup-drivers" class="headerlink" title="2.2 配置cgroup drivers"></a>2.2 配置cgroup drivers</h2><p>CentOS7使用的是<code>systemd</code>来初始化系统并管理进程，初始化进程会生成并使用一个 root 控制组 (<code>cgroup</code>), 并充当 <code>cgroup</code> 管理器。 <code>Systemd</code> 与 <code>cgroup</code> 集成紧密，并将为每个 <code>systemd</code> 单元分配一个 <code>cgroup</code>。 我们也可以配置<code>容器运行时</code>和 <code>kubelet</code> 使用 <code>cgroupfs</code>。 连同 <code>systemd</code> 一起使用 <code>cgroupfs</code> 意味着将有两个不同的 <code>cgroup 管理器</code>。而当一个系统中同时存在cgroupfs和systemd两者时，容易变得不稳定，因此最好更改设置，令容器运行时和 kubelet 使用 <code>systemd</code> 作为 <code>cgroup</code> 驱动，以此使系统更为稳定。 对于 Docker, 需要设置 <code>native.cgroupdriver=systemd</code> 参数。</p>
<blockquote>
<p>参考官方的说明文档：</p>
<p><a target="_blank" rel="noopener" href="https://kubernetes.io/docs/setup/production-environment/container-runtimes/#cgroup-drivers">https://kubernetes.io/docs/setup/production-environment/container-runtimes/#cgroup-drivers</a></p>
<p>参考配置说明文档</p>
<p><a target="_blank" rel="noopener" href="https://kubernetes.io/zh/docs/setup/production-environment/container-runtimes/#docker">https://kubernetes.io/zh/docs/setup/production-environment/container-runtimes/#docker</a></p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">sudo <span class="hljs-built_in">mkdir</span> /etc/docker<br><span class="hljs-built_in">cat</span> &lt;&lt;<span class="hljs-string">EOF | sudo tee /etc/docker/daemon.json</span><br><span class="hljs-string">&#123;</span><br><span class="hljs-string">  &quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;],</span><br><span class="hljs-string">  &quot;log-driver&quot;: &quot;json-file&quot;,</span><br><span class="hljs-string">  &quot;log-opts&quot;: &#123;</span><br><span class="hljs-string">    &quot;max-size&quot;: &quot;100m&quot;</span><br><span class="hljs-string">  &#125;,</span><br><span class="hljs-string">  &quot;storage-driver&quot;: &quot;overlay2&quot;</span><br><span class="hljs-string">&#125;</span><br><span class="hljs-string">EOF</span><br><br>sudo systemctl <span class="hljs-built_in">enable</span> docker<br>sudo systemctl daemon-reload<br>sudo systemctl restart docker<br><br><br><span class="hljs-comment"># 最后检查一下Cgroup Driver是否为systemd</span><br>$ docker info | grep systemd<br> Cgroup Driver: systemd<br></code></pre></div></td></tr></table></figure>

<h2 id="2-3-关于kubelet的cgroup-driver"><a href="#2-3-关于kubelet的cgroup-driver" class="headerlink" title="2.3 关于kubelet的cgroup driver"></a>2.3 关于kubelet的cgroup driver</h2><p>k8s官方有<a target="_blank" rel="noopener" href="https://kubernetes.io/docs/tasks/administer-cluster/kubeadm/configure-cgroup-driver/">详细的文档</a>介绍了如何设置kubelet的<code>cgroup driver</code>，需要特别注意的是，在1.22版本开始，如果没有手动设置kubelet的cgroup driver，那么默认会设置为systemd</p>
<blockquote>
<p><strong>Note:</strong> In v1.22, if the user is not setting the <code>cgroupDriver</code> field under <code>KubeletConfiguration</code>, <code>kubeadm</code> will default it to <code>systemd</code>.</p>
</blockquote>
<p>一个比较简单的指定kubelet的<code>cgroup driver</code>的方法就是在<code>kubeadm-config.yaml</code>加入<code>cgroupDriver</code>字段</p>
<figure class="highlight yaml"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs yaml"><span class="hljs-comment"># kubeadm-config.yaml</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">ClusterConfiguration</span><br><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">kubeadm.k8s.io/v1beta3</span><br><span class="hljs-attr">kubernetesVersion:</span> <span class="hljs-string">v1.21.0</span><br><span class="hljs-meta">---</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">KubeletConfiguration</span><br><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">kubelet.config.k8s.io/v1beta1</span><br><span class="hljs-attr">cgroupDriver:</span> <span class="hljs-string">systemd</span><br></code></pre></div></td></tr></table></figure>

<p>我们可以直接查看configmaps来查看初始化之后集群的kubeadm-config配置。</p>
<figure class="highlight asciidoc"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs asciidoc">$ kubectl describe configmaps kubeadm-config -n kube-system<br>Name:         kubeadm-config<br>Namespace:    kube-system<br>Labels:       &lt;none&gt;<br>Annotations:  &lt;none&gt;<br><br><span class="hljs-section">Data</span><br><span class="hljs-section">====</span><br><span class="hljs-section">ClusterConfiguration:</span><br><span class="hljs-section">----</span><br>apiServer:<br><span class="hljs-code">  extraArgs:</span><br><span class="hljs-code">    authorization-mode: Node,RBAC</span><br><span class="hljs-code">  timeoutForControlPlane: 4m0s</span><br>apiVersion: kubeadm.k8s.io/v1beta3<br>certificatesDir: /etc/kubernetes/pki<br>clusterName: kubernetes<br>controllerManager: &#123;&#125;<br>dns: &#123;&#125;<br>etcd:<br><span class="hljs-code">  local:</span><br><span class="hljs-code">    dataDir: /var/lib/etcd</span><br>imageRepository: registry.aliyuncs.com/google_containers<br>kind: ClusterConfiguration<br>kubernetesVersion: v1.23.6<br>networking:<br><span class="hljs-code">  dnsDomain: cali-cluster.tclocal</span><br><span class="hljs-code">  serviceSubnet: 10.88.0.0/18</span><br>scheduler: &#123;&#125;<br><br><br><span class="hljs-section">BinaryData</span><br><span class="hljs-section">====</span><br><br>Events:  &lt;none&gt;<br></code></pre></div></td></tr></table></figure>

<p>当然因为我们需要安装的版本高于1.22.0并且使用的就是systemd，因此可以不用再重复配置。</p>
<h1 id="3、安装kube三件套"><a href="#3、安装kube三件套" class="headerlink" title="3、安装kube三件套"></a>3、安装kube三件套</h1><blockquote>
<p>对应的官方文档可以参考这里</p>
<p><a target="_blank" rel="noopener" href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/#installing-kubeadm-kubelet-and-kubectl">https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/#installing-kubeadm-kubelet-and-kubectl</a></p>
</blockquote>
<p>kube三件套就是<code>kubeadm</code>、<code>kubelet</code> 和 <code>kubectl</code>，三者的具体功能和作用如下：</p>
<ul>
<li><code>kubeadm</code>：用来初始化集群的指令。</li>
<li><code>kubelet</code>：在集群中的每个节点上用来启动 Pod 和容器等。</li>
<li><code>kubectl</code>：用来与集群通信的命令行工具。</li>
</ul>
<p>需要注意的是：</p>
<ul>
<li><code>kubeadm</code>不会帮助我们管理<code>kubelet</code>和<code>kubectl</code>，其他两者也是一样的，也就是说这三者是相互独立的，并不存在谁管理谁的情况；</li>
<li><code>kubelet</code>的版本必须小于等于<code>API-server</code>的版本，否则容易出现兼容性的问题；</li>
<li><code>kubectl</code>并不是集群中的每个节点都需要安装，也并不是一定要安装在集群中的节点，可以单独安装在自己本地的机器环境上面，然后配合<code>kubeconfig</code>文件即可使用<code>kubectl</code>命令来远程管理对应的k8s集群；</li>
</ul>
<p>CentOS7的安装比较简单，我们直接使用官方提供的<code>yum</code>源即可。需要注意的是这里需要设置<code>selinux</code>的状态，但是前面我们已经关闭了selinux，因此这里略过这步。</p>
<figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash"><span class="hljs-comment"># 直接导入谷歌官方的yum源</span><br><span class="hljs-built_in">cat</span> &lt;&lt;<span class="hljs-string">EOF | sudo tee /etc/yum.repos.d/kubernetes.repo</span><br><span class="hljs-string">[kubernetes]</span><br><span class="hljs-string">name=Kubernetes</span><br><span class="hljs-string">baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-\$basearch</span><br><span class="hljs-string">enabled=1</span><br><span class="hljs-string">gpgcheck=1</span><br><span class="hljs-string">repo_gpgcheck=1</span><br><span class="hljs-string">gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg</span><br><span class="hljs-string">exclude=kubelet kubeadm kubectl</span><br><span class="hljs-string">EOF</span><br><br><span class="hljs-comment"># 当然如果连不上谷歌的源，可以考虑使用国内的阿里镜像源</span><br><span class="hljs-built_in">cat</span> &lt;&lt;<span class="hljs-string">EOF &gt; /etc/yum.repos.d/kubernetes.repo</span><br><span class="hljs-string">[kubernetes]</span><br><span class="hljs-string">name=Kubernetes</span><br><span class="hljs-string">baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/</span><br><span class="hljs-string">enabled=1</span><br><span class="hljs-string">gpgcheck=1</span><br><span class="hljs-string">repo_gpgcheck=1</span><br><span class="hljs-string">gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg</span><br><span class="hljs-string">EOF</span><br><br><br><span class="hljs-comment"># 接下来直接安装三件套即可</span><br>sudo yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes<br><br><span class="hljs-comment"># 如果网络环境不好出现gpgcheck验证失败导致无法正常读取yum源，可以考虑关闭该yum源的repo_gpgcheck</span><br>sed -i <span class="hljs-string">&#x27;s/repo_gpgcheck=1/repo_gpgcheck=0/g&#x27;</span> /etc/yum.repos.d/kubernetes.repo<br><span class="hljs-comment"># 或者在安装的时候禁用gpgcheck</span><br>sudo yum install -y kubelet kubeadm kubectl --nogpgcheck --disableexcludes=kubernetes<br><br><br><br><span class="hljs-comment"># 如果想要安装特定版本，可以使用这个命令查看相关版本的信息</span><br>sudo yum list --nogpgcheck kubelet kubeadm kubectl --showduplicates --disableexcludes=kubernetes<br><span class="hljs-comment"># 这里我们为了保留使用docker-shim，因此我们按照1.24.0版本的前一个版本1.23.6</span><br>sudo yum install -y kubelet-1.23.6-0 kubeadm-1.23.6-0 kubectl-1.23.6-0 --nogpgcheck --disableexcludes=kubernetes<br><br><span class="hljs-comment"># 安装完成后配置开机自启kubelet</span><br>sudo systemctl <span class="hljs-built_in">enable</span> --now kubelet<br></code></pre></div></td></tr></table></figure>

<h1 id="4、初始化集群"><a href="#4、初始化集群" class="headerlink" title="4、初始化集群"></a>4、初始化集群</h1><h2 id="4-1-编写配置文件"><a href="#4-1-编写配置文件" class="headerlink" title="4.1 编写配置文件"></a>4.1 编写配置文件</h2><p>在集群中所有节点都执行完上面的三点操作之后，我们就可以开始创建k8s集群了。因为我们这次不涉及高可用部署，因此初始化的时候直接在我们的目标master节点上面操作即可。</p>
<figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash"><span class="hljs-comment"># 我们先使用kubeadm命令查看一下主要的几个镜像版本</span><br><span class="hljs-comment"># 因为我们此前指定安装了旧的1.23.6版本，这里的apiserver镜像版本也会随之回滚</span><br>$ kubeadm config images list<br>I0506 11:24:17.061315   16055 version.go:255] remote version is much newer: v1.24.0; falling back to: stable-1.23<br>k8s.gcr.io/kube-apiserver:v1.23.6<br>k8s.gcr.io/kube-controller-manager:v1.23.6<br>k8s.gcr.io/kube-scheduler:v1.23.6<br>k8s.gcr.io/kube-proxy:v1.23.6<br>k8s.gcr.io/pause:3.6<br>k8s.gcr.io/etcd:3.5.1-0<br>k8s.gcr.io/coredns/coredns:v1.8.6<br><br><span class="hljs-comment"># 为了方便编辑和管理，我们还是把初始化参数导出成配置文件</span><br>$ kubeadm config <span class="hljs-built_in">print</span> init-defaults &gt; kubeadm-calico.conf<br><br></code></pre></div></td></tr></table></figure>

<ul>
<li>考虑到大多数情况下国内的网络无法使用谷歌的k8s.gcr.io镜像源，我们可以直接在配置文件中修改<code>imageRepository</code>参数为阿里的镜像源</li>
<li><code>kubernetesVersion</code>字段用来指定我们要安装的k8s版本</li>
<li><code>localAPIEndpoint</code>参数需要修改为我们的master节点的IP和端口，初始化之后的k8s集群的apiserver地址就是这个</li>
<li><code>serviceSubnet</code>和<code>dnsDomain</code>两个参数默认情况下可以不用修改，这里我按照自己的需求进行了变更</li>
<li><code>nodeRegistration</code>里面的<code>name</code>参数修改为对应master节点的<code>hostname</code></li>
<li>新增配置块使用ipvs，具体可以参考<a target="_blank" rel="noopener" href="https://github.com/kubernetes/kubernetes/blob/master/pkg/proxy/ipvs/README.md#cluster-created-by-kubeadm">官方文档</a></li>
</ul>
<figure class="highlight yaml"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs yaml"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">kubeadm.k8s.io/v1beta3</span><br><span class="hljs-attr">bootstrapTokens:</span><br><span class="hljs-bullet">-</span> <span class="hljs-attr">groups:</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-string">system:bootstrappers:kubeadm:default-node-token</span><br>  <span class="hljs-attr">token:</span> <span class="hljs-string">abcdef.0123456789abcdef</span><br>  <span class="hljs-attr">ttl:</span> <span class="hljs-string">24h0m0s</span><br>  <span class="hljs-attr">usages:</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-string">signing</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-string">authentication</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">InitConfiguration</span><br><span class="hljs-attr">localAPIEndpoint:</span><br>  <span class="hljs-attr">advertiseAddress:</span> <span class="hljs-number">10.31</span><span class="hljs-number">.88</span><span class="hljs-number">.1</span><br>  <span class="hljs-attr">bindPort:</span> <span class="hljs-number">6443</span><br><span class="hljs-attr">nodeRegistration:</span><br>  <span class="hljs-attr">criSocket:</span> <span class="hljs-string">/var/run/dockershim.sock</span><br>  <span class="hljs-attr">imagePullPolicy:</span> <span class="hljs-string">IfNotPresent</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">tiny-calico-master-88-1.k8s.tcinternal</span><br>  <span class="hljs-attr">taints:</span> <span class="hljs-literal">null</span><br><span class="hljs-meta">---</span><br><span class="hljs-attr">apiServer:</span><br>  <span class="hljs-attr">timeoutForControlPlane:</span> <span class="hljs-string">4m0s</span><br><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">kubeadm.k8s.io/v1beta3</span><br><span class="hljs-attr">certificatesDir:</span> <span class="hljs-string">/etc/kubernetes/pki</span><br><span class="hljs-attr">clusterName:</span> <span class="hljs-string">kubernetes</span><br><span class="hljs-attr">controllerManager:</span> &#123;&#125;<br><span class="hljs-attr">dns:</span> &#123;&#125;<br><span class="hljs-attr">etcd:</span><br>  <span class="hljs-attr">local:</span><br>    <span class="hljs-attr">dataDir:</span> <span class="hljs-string">/var/lib/etcd</span><br><span class="hljs-attr">imageRepository:</span> <span class="hljs-string">registry.aliyuncs.com/google_containers</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">ClusterConfiguration</span><br><span class="hljs-attr">kubernetesVersion:</span> <span class="hljs-number">1.23</span><span class="hljs-number">.6</span><br><span class="hljs-attr">networking:</span><br>  <span class="hljs-attr">dnsDomain:</span> <span class="hljs-string">cali-cluster.tclocal</span><br>  <span class="hljs-attr">serviceSubnet:</span> <span class="hljs-number">10.88</span><span class="hljs-number">.0</span><span class="hljs-number">.0</span><span class="hljs-string">/18</span><br><span class="hljs-attr">scheduler:</span> &#123;&#125;<br><span class="hljs-meta">---</span><br><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">kubeproxy.config.k8s.io/v1alpha1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">KubeProxyConfiguration</span><br><span class="hljs-attr">mode:</span> <span class="hljs-string">ipvs</span><br></code></pre></div></td></tr></table></figure>

<h2 id="4-2-初始化集群"><a href="#4-2-初始化集群" class="headerlink" title="4.2 初始化集群"></a>4.2 初始化集群</h2><p>此时我们再查看对应的配置文件中的镜像版本，就会发现已经变成了对应阿里云镜像源的版本</p>
<figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash"><span class="hljs-comment"># 查看一下对应的镜像版本，确定配置文件是否生效</span><br>$ kubeadm config images list --config kubeadm-calico.conf<br>registry.aliyuncs.com/google_containers/kube-apiserver:v1.23.6<br>registry.aliyuncs.com/google_containers/kube-controller-manager:v1.23.6<br>registry.aliyuncs.com/google_containers/kube-scheduler:v1.23.6<br>registry.aliyuncs.com/google_containers/kube-proxy:v1.23.6<br>registry.aliyuncs.com/google_containers/pause:3.6<br>registry.aliyuncs.com/google_containers/etcd:3.5.1-0<br>registry.aliyuncs.com/google_containers/coredns:v1.8.6<br><br><span class="hljs-comment"># 确认没问题之后我们直接拉取镜像</span><br>$ kubeadm config images pull --config kubeadm-calico.conf<br>[config/images] Pulled registry.aliyuncs.com/google_containers/kube-apiserver:v1.23.6<br>[config/images] Pulled registry.aliyuncs.com/google_containers/kube-controller-manager:v1.23.6<br>[config/images] Pulled registry.aliyuncs.com/google_containers/kube-scheduler:v1.23.6<br>[config/images] Pulled registry.aliyuncs.com/google_containers/kube-proxy:v1.23.6<br>[config/images] Pulled registry.aliyuncs.com/google_containers/pause:3.6<br>[config/images] Pulled registry.aliyuncs.com/google_containers/etcd:3.5.1-0<br>[config/images] Pulled registry.aliyuncs.com/google_containers/coredns:v1.8.6<br><br><span class="hljs-comment"># 初始化</span><br>$ kubeadm init --config kubeadm-calico.conf<br>[init] Using Kubernetes version: v1.23.6<br>[preflight] Running pre-flight checks<br>[preflight] Pulling images required <span class="hljs-keyword">for</span> setting up a Kubernetes cluster<br>[preflight] This might take a minute or two, depending on the speed of your internet connection<br>[preflight] You can also perform this action <span class="hljs-keyword">in</span> beforehand using <span class="hljs-string">&#x27;kubeadm config images pull&#x27;</span><br>...此处略去一堆输出...<br></code></pre></div></td></tr></table></figure>
<p>当我们看到下面这个输出结果的时候，我们的集群就算是初始化成功了。</p>
<figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">Your Kubernetes control-plane has initialized successfully!<br><br>To start using your cluster, you need to run the following as a regular user:<br><br>  <span class="hljs-built_in">mkdir</span> -p <span class="hljs-variable">$HOME</span>/.kube<br>  sudo <span class="hljs-built_in">cp</span> -i /etc/kubernetes/admin.conf <span class="hljs-variable">$HOME</span>/.kube/config<br>  sudo <span class="hljs-built_in">chown</span> $(<span class="hljs-built_in">id</span> -u):$(<span class="hljs-built_in">id</span> -g) <span class="hljs-variable">$HOME</span>/.kube/config<br><br>Alternatively, <span class="hljs-keyword">if</span> you are the root user, you can run:<br><br>  <span class="hljs-built_in">export</span> KUBECONFIG=/etc/kubernetes/admin.conf<br><br>You should now deploy a pod network to the cluster.<br>Run <span class="hljs-string">&quot;kubectl apply -f [podnetwork].yaml&quot;</span> with one of the options listed at:<br>  https://kubernetes.io/docs/concepts/cluster-administration/addons/<br><br>Then you can <span class="hljs-built_in">join</span> any number of worker nodes by running the following on each as root:<br><br>kubeadm <span class="hljs-built_in">join</span> 10.31.88.1:6443 --token abcdef.0123456789abcdef \<br>        --discovery-token-ca-cert-hash sha256:a4189d36d164a865be540d48fcd10ff13e2f90ed6e901201b6ea2baf96dae0ae<br><br></code></pre></div></td></tr></table></figure>

<h2 id="4-3-配置kubeconfig"><a href="#4-3-配置kubeconfig" class="headerlink" title="4.3 配置kubeconfig"></a>4.3 配置kubeconfig</h2><p>刚初始化成功之后，我们还没办法马上查看k8s集群信息，需要配置kubeconfig相关参数才能正常使用kubectl连接apiserver读取集群信息。</p>
<figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash"><span class="hljs-comment"># 对于非root用户，可以这样操作</span><br><span class="hljs-built_in">mkdir</span> -p <span class="hljs-variable">$HOME</span>/.kube<br>sudo <span class="hljs-built_in">cp</span> -i /etc/kubernetes/admin.conf <span class="hljs-variable">$HOME</span>/.kube/config<br>sudo <span class="hljs-built_in">chown</span> $(<span class="hljs-built_in">id</span> -u):$(<span class="hljs-built_in">id</span> -g) <span class="hljs-variable">$HOME</span>/.kube/config<br><br><span class="hljs-comment"># 如果是root用户，可以直接导入环境变量</span><br><span class="hljs-built_in">export</span> KUBECONFIG=/etc/kubernetes/admin.conf<br><br><span class="hljs-comment"># 添加kubectl的自动补全功能</span><br><span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;source &lt;(kubectl completion bash)&quot;</span> &gt;&gt; ~/.bashrc<br></code></pre></div></td></tr></table></figure>

<blockquote>
<p>前面我们提到过<code>kubectl</code>不一定要安装在集群内，实际上只要是任何一台能连接到<code>apiserver</code>的机器上面都可以安装<code>kubectl</code>并且根据步骤配置<code>kubeconfig</code>，就可以使用<code>kubectl</code>命令行来管理对应的k8s集群。</p>
</blockquote>
<p>配置完成后，我们再执行相关命令就可以查看集群的信息了。</p>
<figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ kubectl cluster-info<br>Kubernetes control plane is running at https://10.31.88.1:6443<br>CoreDNS is running at https://10.31.88.1:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy<br><br>To further debug and diagnose cluster problems, use <span class="hljs-string">&#x27;kubectl cluster-info dump&#x27;</span><br><br>$ kubectl get nodes -o wide<br>NAME                                     STATUS     ROLES                  AGE     VERSION   INTERNAL-IP   EXTERNAL-IP   OS-IMAGE                KERNEL-VERSION                CONTAINER-RUNTIME<br>tiny-calico-master-88-1.k8s.tcinternal   NotReady   control-plane,master   4m15s   v1.23.6   10.31.88.1    &lt;none&gt;        CentOS Linux 7 (Core)   3.10.0-1160.62.1.el7.x86_64   docker://20.10.14<br><br>$ kubectl get pods -A -o wide<br>NAMESPACE     NAME                                                             READY   STATUS    RESTARTS   AGE     IP           NODE                                     NOMINATED NODE   READINESS GATES<br>kube-system   coredns-6d8c4cb4d-r8r9q                                          0/1     Pending   0          4m20s   &lt;none&gt;       &lt;none&gt;                                   &lt;none&gt;           &lt;none&gt;<br>kube-system   coredns-6d8c4cb4d-ztq6w                                          0/1     Pending   0          4m20s   &lt;none&gt;       &lt;none&gt;                                   &lt;none&gt;           &lt;none&gt;<br>kube-system   etcd-tiny-calico-master-88-1.k8s.tcinternal                      1/1     Running   0          4m25s   10.31.88.1   tiny-calico-master-88-1.k8s.tcinternal   &lt;none&gt;           &lt;none&gt;<br>kube-system   kube-apiserver-tiny-calico-master-88-1.k8s.tcinternal            1/1     Running   0          4m26s   10.31.88.1   tiny-calico-master-88-1.k8s.tcinternal   &lt;none&gt;           &lt;none&gt;<br>kube-system   kube-controller-manager-tiny-calico-master-88-1.k8s.tcinternal   1/1     Running   0          4m27s   10.31.88.1   tiny-calico-master-88-1.k8s.tcinternal   &lt;none&gt;           &lt;none&gt;<br>kube-system   kube-proxy-v6cg9                                                 1/1     Running   0          4m20s   10.31.88.1   tiny-calico-master-88-1.k8s.tcinternal   &lt;none&gt;           &lt;none&gt;<br>kube-system   kube-scheduler-tiny-calico-master-88-1.k8s.tcinternal            1/1     Running   0          4m25s   10.31.88.1   tiny-calico-master-88-1.k8s.tcinternal   &lt;none&gt;           &lt;none&gt;<br></code></pre></div></td></tr></table></figure>

<h2 id="4-4-添加worker节点"><a href="#4-4-添加worker节点" class="headerlink" title="4.4 添加worker节点"></a>4.4 添加worker节点</h2><p>这时候我们还需要继续添加剩下的两个节点作为worker节点运行负载，直接在剩下的节点上面运行集群初始化成功时输出的命令就可以成功加入集群：</p>
<figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ kubeadm <span class="hljs-built_in">join</span> 10.31.88.1:6443 --token abcdef.0123456789abcdef \<br>&gt;         --discovery-token-ca-cert-hash sha256:a4189d36d164a865be540d48fcd10ff13e2f90ed6e901201b6ea2baf96dae0ae<br>[preflight] Running pre-flight checks<br>[preflight] Reading configuration from the cluster...<br>[preflight] FYI: You can look at this config file with <span class="hljs-string">&#x27;kubectl -n kube-system get cm kubeadm-config -o yaml&#x27;</span><br>[kubelet-start] Writing kubelet configuration to file <span class="hljs-string">&quot;/var/lib/kubelet/config.yaml&quot;</span><br>[kubelet-start] Writing kubelet environment file with flags to file <span class="hljs-string">&quot;/var/lib/kubelet/kubeadm-flags.env&quot;</span><br>[kubelet-start] Starting the kubelet<br>[kubelet-start] Waiting <span class="hljs-keyword">for</span> the kubelet to perform the TLS Bootstrap...<br><br>This node has joined the cluster:<br>* Certificate signing request was sent to apiserver and a response was received.<br>* The Kubelet was informed of the new secure connection details.<br><br>Run <span class="hljs-string">&#x27;kubectl get nodes&#x27;</span> on the control-plane to see this node <span class="hljs-built_in">join</span> the cluster.<br></code></pre></div></td></tr></table></figure>

<p>如果不小心没保存初始化成功的输出信息也没有关系，我们可以使用kubectl工具查看或者生成token</p>
<figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash"><span class="hljs-comment"># 查看现有的token列表</span><br>$ kubeadm token list<br>TOKEN                     TTL         EXPIRES                USAGES                   DESCRIPTION                                                EXTRA GROUPS<br>abcdef.0123456789abcdef   23h         2022-05-07T05:19:08Z   authentication,signing   &lt;none&gt;                                                     system:bootstrappers:kubeadm:default-node-token<br><br><span class="hljs-comment"># 如果token已经失效，那就再创建一个新的token</span><br>$ kubeadm token create<br>e31cv1.lbtrzwp6mzon78ue<br>$ kubeadm token list<br>TOKEN                     TTL         EXPIRES                USAGES                   DESCRIPTION                                                EXTRA GROUPS<br>abcdef.0123456789abcdef   23h         2022-05-07T05:19:08Z   authentication,signing   &lt;none&gt;                                                     system:bootstrappers:kubeadm:default-node-token<br>e31cv1.lbtrzwp6mzon78ue   23h         2022-05-07T05:51:40Z   authentication,signing   &lt;none&gt;                                                     system:bootstrappers:kubeadm:default-node-token<br><br><span class="hljs-comment"># 如果找不到--discovery-token-ca-cert-hash参数，则可以在master节点上使用openssl工具来获取</span><br>$ openssl x509 -pubkey -<span class="hljs-keyword">in</span> /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2&gt;/dev/null |    openssl dgst -sha256 -hex | sed <span class="hljs-string">&#x27;s/^.* //&#x27;</span><br>a4189d36d164a865be540d48fcd10ff13e2f90ed6e901201b6ea2baf96dae0ae<br></code></pre></div></td></tr></table></figure>



<p>添加完成之后我们再查看集群的节点可以发现这时候已经多了两个node，但是此时节点的状态还是<code>NotReady</code>，接下来就需要部署CNI了。</p>
<figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ kubectl get nodes<br>NAME                                      STATUS     ROLES                  AGE    VERSION<br>tiny-calico-master-88-1.k8s.tcinternal    NotReady   control-plane,master   20m    v1.23.6<br>tiny-calico-worker-88-11.k8s.tcinternal   NotReady   &lt;none&gt;                 105s   v1.23.6<br>tiny-calico-worker-88-12.k8s.tcinternal   NotReady   &lt;none&gt;                 35s    v1.23.6<br></code></pre></div></td></tr></table></figure>

<h1 id="5、安装CNI"><a href="#5、安装CNI" class="headerlink" title="5、安装CNI"></a>5、安装CNI</h1><h2 id="5-1-编写manifest文件"><a href="#5-1-编写manifest文件" class="headerlink" title="5.1 编写manifest文件"></a>5.1 编写manifest文件</h2><p>calico的安装也比较简单，官方提供了多种<a target="_blank" rel="noopener" href="https://projectcalico.docs.tigera.io/getting-started/kubernetes/">安装方式</a>，我们这里使用<code>yaml</code>（<a target="_blank" rel="noopener" href="https://projectcalico.docs.tigera.io/getting-started/kubernetes/installation/config-options">自定义manifests</a>）进行安装，并且使用<code>etcd</code>作为<code>datastore</code>。</p>
<figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash"><span class="hljs-comment"># 我们先把官方的yaml模板下载下来，然后对关键字段逐个修改</span><br>curl https://projectcalico.docs.tigera.io/manifests/calico-etcd.yaml -O<br></code></pre></div></td></tr></table></figure>

<p>针对<code>calico-etcd.yaml</code>文件，我们需要修改一些参数以适配我们的集群：</p>
<ul>
<li><p><code>CALICO_IPV4POOL_CIDR</code>参数，配置的是pod的网段，这里我们使用此前计划好的<code>10.88.64.0/18</code>；<code>CALICO_IPV4POOL_BLOCK_SIZE</code>参数，配置的是分配子网的大小，默认是<code>26</code></p>
<figure class="highlight yaml"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs yaml"><span class="hljs-comment"># The default IPv4 pool to create on startup if none exists. Pod IPs will be</span><br><span class="hljs-comment"># chosen from this range. Changing this value after installation will have</span><br><span class="hljs-comment"># no effect. This should fall within `--cluster-cidr`.</span><br><span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">CALICO_IPV4POOL_CIDR</span><br>  <span class="hljs-attr">value:</span> <span class="hljs-string">&quot;10.88.64.0/18&quot;</span><br><span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">CALICO_IPV4POOL_BLOCK_SIZE</span><br>  <span class="hljs-attr">value:</span> <span class="hljs-string">&quot;26&quot;</span><br></code></pre></div></td></tr></table></figure>
</li>
<li><p><code>CALICO_IPV4POOL_IPIP</code>参数，控制是否启用ip-ip模式，默认情况下是<code>Always</code>，由于我们的节点都在同一个二层网络，这里修改为<code>Never</code>或者是<code>CrossSubnet</code>都可以。</p>
<p>其中<code>Never</code>表示不启用ip-ip模式，而<code>CrossSubnet</code>则表示仅当跨子网的时候才启用ip-ip模式</p>
<figure class="highlight yaml"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs yaml"><span class="hljs-comment"># Enable IPIP</span><br><span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">CALICO_IPV4POOL_IPIP</span><br>  <span class="hljs-attr">value:</span> <span class="hljs-string">&quot;Never&quot;</span><br></code></pre></div></td></tr></table></figure>
</li>
<li><p><code>ConfigMap</code>里面的<code>etcd_endpoints</code>变量配置<code>etcd</code>的连接端口和地址，为了安全我们这里开启<code>TLS</code>认证，当然如果不想配置证书的，也可以不使用TLS，然后这三个字段直接留空不做修改</p>
<figure class="highlight yaml"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs yaml"><span class="hljs-attr">kind:</span> <span class="hljs-string">ConfigMap</span><br><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">calico-config</span><br>  <span class="hljs-attr">namespace:</span> <span class="hljs-string">kube-system</span><br><span class="hljs-attr">data:</span><br>  <span class="hljs-comment"># Configure this with the location of your etcd cluster.</span><br>  <span class="hljs-comment"># etcd_endpoints: &quot;http://&lt;ETCD_IP&gt;:&lt;ETCD_PORT&gt;&quot;</span><br>  <span class="hljs-comment"># If you&#x27;re using TLS enabled etcd uncomment the following.</span><br>  <span class="hljs-comment"># You must also populate the Secret below with these files.</span><br>  <span class="hljs-comment"># etcd_ca: &quot;&quot;   # &quot;/calico-secrets/etcd-ca&quot;</span><br>  <span class="hljs-comment"># etcd_cert: &quot;&quot; # &quot;/calico-secrets/etcd-cert&quot;</span><br>  <span class="hljs-comment"># etcd_key: &quot;&quot;  # &quot;/calico-secrets/etcd-key&quot;</span><br>  <span class="hljs-attr">etcd_endpoints:</span> <span class="hljs-string">&quot;https://10.31.88.1:2379&quot;</span><br>  <span class="hljs-attr">etcd_ca:</span> <span class="hljs-string">&quot;/etc/kubernetes/pki/etcd/ca.crt&quot;</span><br>  <span class="hljs-attr">etcd_cert:</span> <span class="hljs-string">&quot;/etc/kubernetes/pki/etcd/server.crt&quot;</span><br>  <span class="hljs-attr">etcd_key:</span> <span class="hljs-string">&quot;/etc/kubernetes/pki/etcd/server.key&quot;</span><br></code></pre></div></td></tr></table></figure>
</li>
<li><p><code>Secret</code>里面的 <code>name: calico-etcd-secrets</code>下面的<code>data</code>字段，需要把上面的三个证书内容使用该命令<code>cat &lt;file&gt; | base64 -w 0</code>转成base64编码格式</p>
<figure class="highlight yaml"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs yaml"><span class="hljs-meta">---</span><br><span class="hljs-comment"># Source: calico/templates/calico-etcd-secrets.yaml</span><br><span class="hljs-comment"># The following contains k8s Secrets for use with a TLS enabled etcd cluster.</span><br><span class="hljs-comment"># For information on populating Secrets, see http://kubernetes.io/docs/user-guide/secrets/</span><br><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">Secret</span><br><span class="hljs-attr">type:</span> <span class="hljs-string">Opaque</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">calico-etcd-secrets</span><br>  <span class="hljs-attr">namespace:</span> <span class="hljs-string">kube-system</span><br><span class="hljs-attr">data:</span><br>  <span class="hljs-comment"># Populate the following with etcd TLS configuration if desired, but leave blank if</span><br>  <span class="hljs-comment"># not using TLS for etcd.</span><br>  <span class="hljs-comment"># The keys below should be uncommented and the values populated with the base64</span><br>  <span class="hljs-comment"># encoded contents of each file that would be associated with the TLS data.</span><br>  <span class="hljs-comment"># Example command for encoding a file contents: cat &lt;file&gt; | base64 -w 0</span><br>  <span class="hljs-attr">etcd-key:</span> <span class="hljs-string">LS0tLS1CRUdJTi......tLS0tCg==</span><br>  <span class="hljs-attr">etcd-cert:</span> <span class="hljs-string">LS0tLS1CRUdJT......tLS0tLQo=</span><br>  <span class="hljs-attr">etcd-ca:</span> <span class="hljs-string">LS0tLS1CRUdJTiB......FLS0tLS0K</span><br></code></pre></div></td></tr></table></figure></li>
</ul>
<h2 id="5-2-部署calico"><a href="#5-2-部署calico" class="headerlink" title="5.2 部署calico"></a>5.2 部署calico</h2><p>修改完成之后我们直接部署即可</p>
<figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ kubectl apply -f calico-etcd.yaml<br>secret/calico-etcd-secrets created<br>configmap/calico-config created<br>clusterrole.rbac.authorization.k8s.io/calico-kube-controllers created<br>clusterrolebinding.rbac.authorization.k8s.io/calico-kube-controllers created<br>clusterrole.rbac.authorization.k8s.io/calico-node created<br>clusterrolebinding.rbac.authorization.k8s.io/calico-node created<br>daemonset.apps/calico-node created<br>serviceaccount/calico-node created<br>deployment.apps/calico-kube-controllers created<br>serviceaccount/calico-kube-controllers created<br>Warning: policy/v1beta1 PodDisruptionBudget is deprecated <span class="hljs-keyword">in</span> v1.21+, unavailable <span class="hljs-keyword">in</span> v1.25+; use policy/v1 PodDisruptionBudget<br>poddisruptionbudget.policy/calico-kube-controllers created<br><br><span class="hljs-comment"># 查看pod是否正常运行</span><br>$ kubectl get pods -A<br>NAMESPACE     NAME                                                             READY   STATUS    RESTARTS        AGE<br>kube-system   calico-kube-controllers-5c4bd49f9b-6b2gr                         1/1     Running   5 (3m18s ago)   6m18s<br>kube-system   calico-node-bgsfs                                                1/1     Running   5 (2m55s ago)   6m18s<br>kube-system   calico-node-tr88g                                                1/1     Running   5 (3m19s ago)   6m18s<br>kube-system   calico-node-w59pc                                                1/1     Running   5 (2m36s ago)   6m18s<br>kube-system   coredns-6d8c4cb4d-r8r9q                                          1/1     Running   0               3h8m<br>kube-system   coredns-6d8c4cb4d-ztq6w                                          1/1     Running   0               3h8m<br>kube-system   etcd-tiny-calico-master-88-1.k8s.tcinternal                      1/1     Running   0               3h8m<br>kube-system   kube-apiserver-tiny-calico-master-88-1.k8s.tcinternal            1/1     Running   0               3h8m<br>kube-system   kube-controller-manager-tiny-calico-master-88-1.k8s.tcinternal   1/1     Running   0               3h8m<br>kube-system   kube-proxy-n65sb                                                 1/1     Running   0               169m<br>kube-system   kube-proxy-qmxhp                                                 1/1     Running   0               168m<br>kube-system   kube-proxy-v6cg9                                                 1/1     Running   0               3h8m<br>kube-system   kube-scheduler-tiny-calico-master-88-1.k8s.tcinternal            1/1     Running   0               3h8m<br><br><span class="hljs-comment"># 查看calico-kube-controllers的pod日志是否有报错</span><br>$ kubectl logs -f calico-kube-controllers-5c4bd49f9b-6b2gr -n kube-system<br></code></pre></div></td></tr></table></figure>

<h2 id="5-3-pod安装calicoctl"><a href="#5-3-pod安装calicoctl" class="headerlink" title="5.3 pod安装calicoctl"></a>5.3 pod安装calicoctl</h2><p>calicoctl是用来查看管理calico的命令行工具，定位上有点类似于calico版本的kubectl，因为我们前面使用了etcd作为calico的datastore，这里直接选择<a target="_blank" rel="noopener" href="https://projectcalico.docs.tigera.io/maintenance/clis/calicoctl/install#install-calicoctl-as-a-kubernetes-pod">在k8s集群中以pod的形式部署</a><code>calicoctl</code>的方式更加简单。</p>
<ul>
<li><code>calicoctl</code>的版本最好和部署的calico一致，这里均为<code>v3.22.2</code></li>
<li><code>calicoctl</code>的etcd配置最好和部署的calico一致，因为前面部署calico的时候etcd开启了TLS，因此这里我们也要修改yaml文件开启TLS</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash"><span class="hljs-comment"># 为了方便后期管理，我们先把calicoctl.yaml下载到本地再进行部署</span><br>$ wget https://projectcalico.docs.tigera.io/manifests/calicoctl-etcd.yaml<br><br>$ <span class="hljs-built_in">cat</span> calicoctl-etcd.yaml<br><span class="hljs-comment"># Calico Version v3.22.2</span><br><span class="hljs-comment"># https://projectcalico.docs.tigera.io/releases#v3.22.2</span><br><span class="hljs-comment"># This manifest includes the following component versions:</span><br><span class="hljs-comment">#   calico/ctl:v3.22.2</span><br><br>apiVersion: v1<br>kind: Pod<br>metadata:<br>  name: calicoctl<br>  namespace: kube-system<br>spec:<br>  nodeSelector:<br>    kubernetes.io/os: linux<br>  hostNetwork: <span class="hljs-literal">true</span><br>  containers:<br>  - name: calicoctl<br>    image: calico/ctl:v3.22.2<br>    <span class="hljs-built_in">command</span>:<br>      - /calicoctl<br>    args:<br>      - version<br>      - --poll=1m<br>    <span class="hljs-built_in">env</span>:<br>    - name: ETCD_ENDPOINTS<br>      valueFrom:<br>        configMapKeyRef:<br>          name: calico-config<br>          key: etcd_endpoints<br>    <span class="hljs-comment"># If you&#x27;re using TLS enabled etcd uncomment the following.</span><br>    <span class="hljs-comment"># Location of the CA certificate for etcd.</span><br>    - name: ETCD_CA_CERT_FILE<br>      valueFrom:<br>        configMapKeyRef:<br>          name: calico-config<br>          key: etcd_ca<br>    <span class="hljs-comment"># Location of the client key for etcd.</span><br>    - name: ETCD_KEY_FILE<br>      valueFrom:<br>        configMapKeyRef:<br>          name: calico-config<br>          key: etcd_key<br>    <span class="hljs-comment"># Location of the client certificate for etcd.</span><br>    - name: ETCD_CERT_FILE<br>      valueFrom:<br>        configMapKeyRef:<br>          name: calico-config<br>          key: etcd_cert<br>    volumeMounts:<br>    - mountPath: /calico-secrets<br>      name: etcd-certs<br>  volumes:<br>    <span class="hljs-comment"># If you&#x27;re using TLS enabled etcd uncomment the following.</span><br>    - name: etcd-certs<br>      secret:<br>        secretName: calico-etcd-secrets<br></code></pre></div></td></tr></table></figure>

<p>修改完成之后我们直接部署即可使用</p>
<figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ kubectl apply -f calicoctl-etcd.yaml<br>pod/calicoctl created<br><br><span class="hljs-comment"># 创建完成后我们查看calicoctl的运行状态</span><br>$ kubectl get pods -A | grep calicoctl<br>kube-system   calicoctl                                                        1/1     Running   0             9s<br><br><span class="hljs-comment"># 检验一下是否能够正常工作</span><br>$ kubectl <span class="hljs-built_in">exec</span> -ti -n kube-system calicoctl -- /calicoctl get nodes<br>NAME<br>tiny-calico-master-88-1.k8s.tcinternal<br>tiny-calico-worker-88-11.k8s.tcinternal<br>tiny-calico-worker-88-12.k8s.tcinternal<br><br>$ kubectl <span class="hljs-built_in">exec</span> -ti -n kube-system calicoctl -- /calicoctl get profiles -o wide<br>NAME                                                 LABELS<br>projectcalico-default-allow<br>kns.default                                          pcns.kubernetes.io/metadata.name=default,pcns.projectcalico.org/name=default<br>kns.kube-node-lease                                  pcns.kubernetes.io/metadata.name=kube-node-lease,pcns.projectcalico.org/name=kube-node-lease<br>kns.kube-public                                      pcns.kubernetes.io/metadata.name=kube-public,pcns.projectcalico.org/name=kube-public<br>kns.kube-system                                      pcns.kubernetes.io/metadata.name=kube-system,pcns.projectcalico.org/name=kube-system<br>...此处略去一堆输出...<br><br><span class="hljs-comment"># 查看ipam的分配情况</span><br>$ calicoctl ipam show<br>+----------+---------------+-----------+------------+--------------+<br>| GROUPING |     CIDR      | IPS TOTAL | IPS IN USE |   IPS FREE   |<br>+----------+---------------+-----------+------------+--------------+<br>| IP Pool  | 10.88.64.0/18 |     16384 | 2 (0%)     | 16382 (100%) |<br>+----------+---------------+-----------+------------+--------------+<br><br><br><span class="hljs-comment"># 为了方便可以在bashrc中设置alias</span><br><span class="hljs-built_in">cat</span> &gt;&gt; ~/.bashrc &lt;&lt;<span class="hljs-string">EOF</span><br><span class="hljs-string">alias calicoctl=&quot;kubectl exec -i -n kube-system calicoctl -- /calicoctl&quot;</span><br><span class="hljs-string">EOF</span><br><br></code></pre></div></td></tr></table></figure>

<p>完整版本calicoctl命令可以参考<a target="_blank" rel="noopener" href="https://projectcalico.docs.tigera.io/reference/calicoctl/">官方文档</a>。</p>
<h2 id="5-4-binary安装calicoctl"><a href="#5-4-binary安装calicoctl" class="headerlink" title="5.4 binary安装calicoctl"></a>5.4 binary安装calicoctl</h2><p>使用pod方式部署<code>calicoctl</code>虽然简单，但是有个问题就是无法使用<code>calicoctl node</code>命令，这个命令需要访问部分宿主机的文件系统。因此这里我们再二进制部署一个<code>calicoctl</code>。</p>
<blockquote>
<p>Note that if you run <code>calicoctl</code> in a container, <code>calicoctl node ...</code> commands will not work (they need access to parts of the host filesystem).</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash"><span class="hljs-comment"># 直接下线二进制文件即可使用</span><br>$ <span class="hljs-built_in">cd</span> /usr/local/bin/<br>$ curl -L https://github.com/projectcalico/calico/releases/download/v3.22.2/calicoctl-linux-amd64 -o calicoctl<br>$ <span class="hljs-built_in">chmod</span> +x ./calicoctl<br></code></pre></div></td></tr></table></figure>

<p>二进制的calicoctl会优先读取配置文件，当找不到配置文件的时候才会去读取环境变量，这里我们直接配置<code>/etc/calico/calicoctl.cfg</code>，注意etcd的证书直接和前面部署calico时使用的证书文件一致即可。</p>
<figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash"><span class="hljs-comment"># 配置calicoctl的配置文件</span><br>$ <span class="hljs-built_in">mkdir</span> /etc/calico<br>$ <span class="hljs-built_in">cat</span> /etc/calico/calicoctl.cfg<br>apiVersion: projectcalico.org/v3<br>kind: CalicoAPIConfig<br>metadata:<br>spec:<br>  datastoreType: etcdv3<br>  etcdEndpoints: <span class="hljs-string">&quot;https://10.31.88.1:2379&quot;</span><br>  etcdCACert: |<br>      -----BEGIN CERTIFICATE-----<br>      MIIC9TCCAd2gAwIBAgIBADANBgkqhkiG9w0BAQsFADASMRAwDgYDVQQDEwdldGNk<br>      LWNhMB4XDTIyMDUwNjA1MTg1OVoXDTMyMDUwMzA1MTg1OVowEjEQMA4GA1UEAxMH<br>      ZXRjZC1jYTCCASIwDQYJKoZIhvcNAQEBBQADggEPADCCAQoCggEBANFFqq4Mk3DE<br>      6UW581xnZPFrHqQWlGr/KptEywKH56Bp24OAnDIAkSz7KAMrJzL+OiVsj9YJV59F<br>      9qH/YzU+bppctDnfk1yCuavkcXgLSd9O6EBhM2LkGtF9AdWMnFw9ui2jNhFC/QXj<br>      zCvq0I1c9o9gulbFmSHwIw2GLQd7ogO+PpfLsubRscJdKkCUWVFV0mb8opccmXoF<br>      vXynRX0VW3wpN+v66bD+HTdMSNK1JljfBngh9LAkibjUx7bMrHvu/GOalNCSWrtG<br>      lss/hhWkzwV7Y7AIXgvxxcmDdfswe5lUYLvW2CP4e+tXfB3i2wg10fErc8z63lix<br>      v9BWkIIalScCAwEAAaNWMFQwDgYDVR0PAQH/BAQDAgKkMA8GA1UdEwEB/wQFMAMB<br>      Af8wHQYDVR0OBBYEFH49PpnJYxze8aq0PVwgpY4Fo6djMBIGA1UdEQQLMAmCB2V0<br>      Y2QtY2EwDQYJKoZIhvcNAQELBQADggEBAAGL6KwN80YEK6gZcL+7RI9bkMKk7UWW<br>      V48154CgN8w9GKvNTm4l0tZKvsWCnR61hiJtLQcG0S8HYHAvL1DBjOXw11bNilLy<br>      vaVM+wqOOIxPsXLU//F46z3V9z1uV0v/yLLlg320c0wtG+OLZZIn8O+yUhtOHM09<br>      K0JSAF2/KhtNxhrc0owCTOzS+DKsb0w1SzQmS0t/tflyLfc3oJZ/2V4Tqd72j7iI<br>      cDBa36lGqtUBf8MXu+Xza0cdhy/f19AqkeM2fe+/DrbzR4zDVmZ7l4dqYGLbKHYo<br>      XaLn8bSToYQq4dlA/oAlyyH0ekB5v0DyYiHwlqgZgiu4qcR3Gw8azVk=<br>      -----END CERTIFICATE-----<br>  etcdCert: |<br>      -----BEGIN CERTIFICATE-----<br>      MIIDgzCCAmugAwIBAgIIePiBSOdMGwcwDQYJKoZIhvcNAQELBQAwEjEQMA4GA1UE<br>      AxMHZXRjZC1jYTAeFw0yMjA1MDYwNTE4NTlaFw0yMzA1MDYwNTE4NTlaMDExLzAt<br>      BgNVBAMTJnRpbnktY2FsaWNvLW1hc3Rlci04OC0xLms4cy50Y2ludGVybmFsMIIB<br>      IjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAqZM/jBrdXLR3ctee7LVJhGSA<br>      4usg/JQXGyOAd52OkkOLYwn3fvwqeo0Z0cX0q4mqaF0cnrPYc4eExX/3fJpF3Fxy<br>      D6vdpEZ/FrnzCAkibEYtK/UVhTKuV7n/VdbjFPGl8CpppuGVs6o+4NFZxffW7em0<br>      8m/FK/7SDkV2qXCyG94kOaUCeDEgdBKE3cPCZQ4maFuwXi08bYs2CiTfbfa4dsT5<br>      3yzaoQVX9BaBqE9IGmsHDFuxp1X8gkJXs+7wwHQX39o1oXmci6T4IVxVHA5GRbTv<br>      pCDG5Wye7QqKgnxO1KRF42FKs1Nif7UJ0iR35Ydpa7cat7Fr0M7l+rZLCDTJgwID<br>      AQABo4G9MIG6MA4GA1UdDwEB/wQEAwIFoDAdBgNVHSUEFjAUBggrBgEFBQcDAQYI<br>      KwYBBQUHAwIwDAYDVR0TAQH/BAIwADAfBgNVHSMEGDAWgBR+PT6ZyWMc3vGqtD1c<br>      IKWOBaOnYzBaBgNVHREEUzBRgglsb2NhbGhvc3SCJnRpbnktY2FsaWNvLW1hc3Rl<br>      ci04OC0xLms4cy50Y2ludGVybmFshwQKH1gBhwR/AAABhxAAAAAAAAAAAAAAAAAA<br>      AAABMA0GCSqGSIb3DQEBCwUAA4IBAQC+pyH14/+US5Svz04Vi8QIduY/DVx1HOQq<br>      hfrIZKOZCH2iKU7fZ4o9QpQZh7D9B8hgpXM6dNuFpd98c0MVPr+LesShu4BHVjHl<br>      gPvUWEVB2XD5x51HqnMV2OkhMKooyAUIzI0P0YKN29SFEyJGD1XDu4UtqvBADqf7<br>      COvAuqj4VbRgF/iQwNstjqZ47rSzvyp6rIwqFoHRP+Zi+8KL1qmozGjI3+H+TZFM<br>      Gv3b5DRx2pmfY+kGVLO5bjl3zxylRPjCDHaRlQUWiOYSWS8OHYRCBZuSLvW4tht0<br>      JjWjUAh4hF8+3lyNrfx8moz7tfm5SG2q01pO1vjkhrhxhINAwaac<br>      -----END CERTIFICATE-----<br>  etcdKey: |<br>      -----BEGIN RSA PRIVATE KEY-----<br>      MIIEowIBAAKCAQEAqZM/jBrdXLR3ctee7LVJhGSA4usg/JQXGyOAd52OkkOLYwn3<br>      fvwqeo0Z0cX0q4mqaF0cnrPYc4eExX/3fJpF3FxyD6vdpEZ/FrnzCAkibEYtK/UV<br>      hTKuV7n/VdbjFPGl8CpppuGVs6o+4NFZxffW7em08m/FK/7SDkV2qXCyG94kOaUC<br>      eDEgdBKE3cPCZQ4maFuwXi08bYs2CiTfbfa4dsT53yzaoQVX9BaBqE9IGmsHDFux<br>      p1X8gkJXs+7wwHQX39o1oXmci6T4IVxVHA5GRbTvpCDG5Wye7QqKgnxO1KRF42FK<br>      s1Nif7UJ0iR35Ydpa7cat7Fr0M7l+rZLCDTJgwIDAQABAoIBAE1gMw7q8zbp4dc1<br>      K/82eWU/ts/UGikmKaTofiYWboeu6ls2oQgAaCGjYLSnbw0Ws/sLAZQo3AtbOuoj<br>      ifoBKv9x71nXQjtDL5pfHtX71QkyvEniev9cMNE2vZudgeB8owsDT1ImfPiOJkLP<br>      Q/dhL2E/0qEM/xskGxUH/S0zjxHHfPZZsYODhkVPWc6Z+XEDll48fRCFn4/48FTN<br>      9GbRvo7dv34EHmNYA20K4DMHbZUdrPqSZpKWzAPJXnDlgZbpvUeAYOJxqZHQtCm1<br>      zbSOyM1Ql6K0Ayro0L5GAzap+0yGuk79OWiPnEsdPneVsATKG7dT7RZIL/INrOqQ<br>      0wjUmQECgYEA02OHdT1K5Au6wtiTqKD99WweltnvFd4C/Z3dobEj8M8qN6uiKCca<br>      PievWahnxAlJEah3RiOgtarwA+0E/Jgsw99Qutp5BR/XdD3llTNczkPkg/RkWpve<br>      2f/4DlZQrxuIem7UNLl+5BacfmF691DQQoX2RoIkvQxYJGTUNXvrSUkCgYEAzVyz<br>      mvN+dvSwzAlm0gkfVP5Ez3DFESUrWd0FR2v1HR6qHQy/dkgkkic6zRGCJtGeT5V7<br>      N0kbVSHsz+wi6aQkFy0Sp0TbgZzjPhSwNtk+2JsBRvMp0CYczgrfyvWuAQ3gbXGc<br>      N8IkcZSSOv8TuigCnnYf2Xaz8LM50AivScnb6GsCgYEAyq4ScgnLpa3NawbnRPbf<br>      qRH6nl7lC01sBqn3mBHVSQ4JB4msF92uHsxEJ639mAvjIGgrvHdqnuT/7nOypVJv<br>      EXsr14ykHpKyLQUv/Idbw3V7RD3ufqYW3WS8/VorUEoQ6HsdQlRc4ur/L3ndwgWd<br>      OTtir6YW/aA5XuPCSGnBZekCgYB6VtlgW+Jg91BDnO41/d0+guN3ONUNa7kxpau5<br>      aqTxHg11lNySmFPBBcHP3LhOa94FxyVKQDEaPEWZcDE0QuaFMALGxwyFYHM3zpdT<br>      dYQtAdp26/Fi4PGUBYJgpI9ubVffmyjXRr7zMvESWFbmNWOqBvDeWgrEP+EW/7V9<br>      HdX11QKBgE1czchlibgQ/bhAl8BatKRr1X/UHvblWhmyApudOfFeGOILR6u/lWvY<br>      SS+Rg0y8nnZ4hTRSXbd/sSEsUJcSmoBc1TivWzl32eVuqe9CcrUZY0JSLtoj1KiP<br>      adRcCZtVDETXbW326Hvgz+MnqrIgzx+Zgy4tNtoAAbTv0q83j45I<br>      -----END RSA PRIVATE KEY-----<br><br></code></pre></div></td></tr></table></figure>

<p>配置完成之后我们检查一下效果</p>
<figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ calicoctl node status<br>Calico process is running.<br><br>IPv4 BGP status<br>+--------------+-------------------+-------+----------+-------------+<br>| PEER ADDRESS |     PEER TYPE     | STATE |  SINCE   |    INFO     |<br>+--------------+-------------------+-------+----------+-------------+<br>| 10.31.88.11  | node-to-node mesh | up    | 08:26:30 | Established |<br>| 10.31.88.12  | node-to-node mesh | up    | 08:26:30 | Established |<br>+--------------+-------------------+-------+----------+-------------+<br><br>IPv6 BGP status<br>No IPv6 peers found.<br><br>$ calicoctl get nodes<br>NAME<br>tiny-calico-master-88-1.k8s.tcinternal<br>tiny-calico-worker-88-11.k8s.tcinternal<br>tiny-calico-worker-88-12.k8s.tcinternal<br><br>$ calicoctl ipam show<br>+----------+---------------+-----------+------------+--------------+<br>| GROUPING |     CIDR      | IPS TOTAL | IPS IN USE |   IPS FREE   |<br>+----------+---------------+-----------+------------+--------------+<br>| IP Pool  | 10.88.64.0/18 |     16384 | 2 (0%)     | 16382 (100%) |<br>+----------+---------------+-----------+------------+--------------+<br></code></pre></div></td></tr></table></figure>

<h1 id="6、部署测试用例"><a href="#6、部署测试用例" class="headerlink" title="6、部署测试用例"></a>6、部署测试用例</h1><p>集群部署完成之后我们在k8s集群中部署一个nginx测试一下是否能够正常工作。首先我们创建一个名为<code>nginx-quic</code>的命名空间（<code>namespace</code>），然后在这个命名空间内创建一个名为<code>nginx-quic-deployment</code>的<code>deployment</code>用来部署pod，最后再创建一个<code>service</code>用来暴露服务，这里我们先使用<code>nodeport</code>的方式暴露端口方便测试。</p>
<figure class="highlight yaml"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs yaml"><span class="hljs-string">$</span> <span class="hljs-string">cat</span> <span class="hljs-string">nginx-quic.yaml</span><br><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">Namespace</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">nginx-quic</span><br><br><span class="hljs-meta">---</span><br><span class="hljs-meta"></span><br><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">apps/v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">Deployment</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">nginx-quic-deployment</span><br>  <span class="hljs-attr">namespace:</span> <span class="hljs-string">nginx-quic</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">selector:</span><br>    <span class="hljs-attr">matchLabels:</span><br>      <span class="hljs-attr">app:</span> <span class="hljs-string">nginx-quic</span><br>  <span class="hljs-attr">replicas:</span> <span class="hljs-number">4</span><br>  <span class="hljs-attr">template:</span><br>    <span class="hljs-attr">metadata:</span><br>      <span class="hljs-attr">labels:</span><br>        <span class="hljs-attr">app:</span> <span class="hljs-string">nginx-quic</span><br>    <span class="hljs-attr">spec:</span><br>      <span class="hljs-attr">containers:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">nginx-quic</span><br>        <span class="hljs-attr">image:</span> <span class="hljs-string">tinychen777/nginx-quic:latest</span><br>        <span class="hljs-attr">imagePullPolicy:</span> <span class="hljs-string">IfNotPresent</span><br>        <span class="hljs-attr">ports:</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-attr">containerPort:</span> <span class="hljs-number">80</span><br><br><span class="hljs-meta">---</span><br><span class="hljs-meta"></span><br><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">Service</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">nginx-quic-service</span><br>  <span class="hljs-attr">namespace:</span> <span class="hljs-string">nginx-quic</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">selector:</span><br>    <span class="hljs-attr">app:</span> <span class="hljs-string">nginx-quic</span><br>  <span class="hljs-attr">ports:</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-attr">protocol:</span> <span class="hljs-string">TCP</span><br>    <span class="hljs-attr">port:</span> <span class="hljs-number">8080</span> <span class="hljs-comment"># match for service access port</span><br>    <span class="hljs-attr">targetPort:</span> <span class="hljs-number">80</span> <span class="hljs-comment"># match for pod access port</span><br>    <span class="hljs-attr">nodePort:</span> <span class="hljs-number">30088</span> <span class="hljs-comment"># match for external access port</span><br>  <span class="hljs-attr">type:</span> <span class="hljs-string">NodePort</span><br></code></pre></div></td></tr></table></figure>

<p>部署完成后我们直接查看状态</p>
<figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash"><span class="hljs-comment"># 直接部署</span><br>$ kubectl apply -f nginx-quic.yaml<br>namespace/nginx-quic created<br>deployment.apps/nginx-quic-deployment created<br>service/nginx-quic-service created<br><br><span class="hljs-comment"># 查看deployment的运行状态</span><br>$ kubectl get deployment -o wide -n nginx-quic<br>NAME                    READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS   IMAGES                          SELECTOR<br>nginx-quic-deployment   4/4     4            4           55s   nginx-quic   tinychen777/nginx-quic:latest   app=nginx-quic<br><br><span class="hljs-comment"># 查看service的运行状态</span><br>$ kubectl get service -o wide -n nginx-quic<br>NAME                 TYPE       CLUSTER-IP     EXTERNAL-IP   PORT(S)          AGE   SELECTOR<br>nginx-quic-service   NodePort   10.88.52.168   &lt;none&gt;        8080:30088/TCP   66s   app=nginx-quic<br><br><span class="hljs-comment"># 查看pod的运行状态</span><br>$ kubectl get pods -o wide -n nginx-quic<br>NAME                                     READY   STATUS    RESTARTS   AGE   IP             NODE                                      NOMINATED NODE   READINESS GATES<br>nginx-quic-deployment-7457f4d579-24q9z   1/1     Running   0          75s   10.88.120.72   tiny-calico-worker-88-12.k8s.tcinternal   &lt;none&gt;           &lt;none&gt;<br>nginx-quic-deployment-7457f4d579-4svv9   1/1     Running   0          75s   10.88.84.68    tiny-calico-worker-88-11.k8s.tcinternal   &lt;none&gt;           &lt;none&gt;<br>nginx-quic-deployment-7457f4d579-btrjj   1/1     Running   0          75s   10.88.120.71   tiny-calico-worker-88-12.k8s.tcinternal   &lt;none&gt;           &lt;none&gt;<br>nginx-quic-deployment-7457f4d579-lvh6x   1/1     Running   0          75s   10.88.84.69    tiny-calico-worker-88-11.k8s.tcinternal   &lt;none&gt;           &lt;none&gt;<br><br><br><span class="hljs-comment"># 查看IPVS规则</span><br>$ ipvsadm -<span class="hljs-built_in">ln</span><br>IP Virtual Server version 1.2.1 (size=4096)<br>Prot LocalAddress:Port Scheduler Flags<br>  -&gt; RemoteAddress:Port           Forward Weight ActiveConn InActConn<br>TCP  172.17.0.1:30088 rr<br>  -&gt; 10.88.84.68:80               Masq    1      0          0<br>  -&gt; 10.88.84.69:80               Masq    1      0          0<br>  -&gt; 10.88.120.71:80              Masq    1      0          0<br>  -&gt; 10.88.120.72:80              Masq    1      0          0<br>TCP  10.31.88.1:30088 rr<br>  -&gt; 10.88.84.68:80               Masq    1      0          0<br>  -&gt; 10.88.84.69:80               Masq    1      0          0<br>  -&gt; 10.88.120.71:80              Masq    1      0          0<br>  -&gt; 10.88.120.72:80              Masq    1      0          0<br>TCP  10.88.52.168:8080 rr<br>  -&gt; 10.88.84.68:80               Masq    1      0          0<br>  -&gt; 10.88.84.69:80               Masq    1      0          0<br>  -&gt; 10.88.120.71:80              Masq    1      0          0<br>  -&gt; 10.88.120.72:80              Masq    1      0          0<br></code></pre></div></td></tr></table></figure>

<p>最后我们进行测试，这个nginx-quic的镜像默认情况下会返回在nginx容器中获得的用户请求的IP和端口</p>
<figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash"><span class="hljs-comment"># 首先我们在集群内进行测试</span><br><span class="hljs-comment"># 直接访问pod</span><br>$ curl 10.88.84.68:80<br>10.31.88.1:34612<br><span class="hljs-comment"># 直接访问service的ClusterIP，这时请求会被转发到pod中</span><br>$ curl 10.88.52.168:8080<br>10.31.88.1:58978<br><span class="hljs-comment"># 直接访问nodeport，这时请求会被转发到pod中，不会经过ClusterIP</span><br>$ curl 10.31.88.1:30088<br>10.31.88.1:56595<br><br><span class="hljs-comment"># 接着我们在集群外进行测试</span><br><span class="hljs-comment"># 直接访问三个节点的nodeport，这时请求会被转发到pod中，不会经过ClusterIP</span><br><span class="hljs-comment"># 由于externalTrafficPolicy默认为Cluster，因此nginx拿到的IP就是我们访问的节点的IP，而非客户端IP</span><br>$ curl 10.31.88.1:30088<br>10.31.88.1:27851<br>$ curl 10.31.88.11:30088<br>10.31.88.11:16540<br>$ curl 10.31.88.12:30088<br>10.31.88.12:5767<br></code></pre></div></td></tr></table></figure>


            </div>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/categories/cloudnative/">cloudnative</a>
                    
                  </div>
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/tags/centos/">centos</a>
                    
                      <a class="hover-with-bg" href="/tags/k8s/">k8s</a>
                    
                      <a class="hover-with-bg" href="/tags/docker/">docker</a>
                    
                      <a class="hover-with-bg" href="/tags/calico/">calico</a>
                    
                  </div>
                
              </div>
              
              
                <div class="post-prevnext">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/20220510-k8s-04-deploy-k8s-with-cilium/">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">k8s系列04-kubeadm部署cilium网络的k8s集群</span>
                        <span class="visible-mobile">Previous</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/20220507-k8s-02-deploy-k8s-with-flannel/">
                        <span class="hidden-mobile">k8s系列02-kubeadm部署flannel网络的k8s集群</span>
                        <span class="visible-mobile">Next</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;TOC</p>
  <div class="toc-body" id="toc-body"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Search</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">keyword</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
    

    
  </main>

  <footer class="text-center mt-5 py-3">
  <div class="footer-content">
     <i class="iconfont icon-copyright"></i> <a href="https://tinychen.com/" target="_blank" rel="nofollow noopener"><span>Since 2017 By TinyChen </span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Hexo-Fluid</span></a> 
  </div>
  

  
  <!-- 备案信息 -->
  <div class="beian">
    <span>
      <a href="http://beian.miit.gov.cn/" target="_blank" rel="nofollow noopener">
        粤ICP备18140640号
      </a>
    </span>
    
  </div>


  
</footer>


  <!-- SCRIPTS -->
  
  <script  src="https://cdn.jsdelivr.net/npm/nprogress@0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js" ></script>
<script  src="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>

<!-- Plugins -->


  <script  src="/js/local-search.js" ></script>



  
    <script  src="/js/img-lazyload.js" ></script>
  



  



  
    <script  src="https://cdn.jsdelivr.net/npm/tocbot@4/dist/tocbot.min.js" ></script>
  
  
    <script  src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3/dist/jquery.fancybox.min.js" ></script>
  
  
    <script  src="https://cdn.jsdelivr.net/npm/anchor-js@4/anchor.min.js" ></script>
  
  
    <script defer src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js" ></script>
  






  <script  src="https://cdn.jsdelivr.net/npm/typed.js@2/lib/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var title = document.getElementById('subtitle').title;
      
        typing(title);
      
    })(window, document);
  </script>












  
    <!-- Baidu Analytics -->
    <script defer>
      var _hmt = _hmt || [];
      (function () {
        var hm = document.createElement("script");
        hm.src = "https://hm.baidu.com/hm.js?7a96963a1145ac7fde1442d739a11ffd";
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(hm, s);
      })();
    </script>
  

  
    <!-- Google Analytics -->
    <script defer>
      window.ga = window.ga || function () { (ga.q = ga.q || []).push(arguments) };
      ga.l = +new Date;
      ga('create', 'UA-166769908-1', 'auto');
      ga('send', 'pageview');
    </script>
    <script async src='https://www.google-analytics.com/analytics.js'></script>
  

  

  

  

  





<!-- 主题的启动项 保持在最底部 -->
<script  src="/js/boot.js" ></script>


</body>
</html>
