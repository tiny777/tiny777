

<!DOCTYPE html>
<html lang="en" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="https://resource.tinychen.com/logos.png">
  <link rel="icon" href="https://resource.tinychen.com/logos.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
    <meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="TinyChen">
  <meta name="keywords" content="">
  
    <meta name="description" content="本文主要在centos7系统上基于docker和cilium组件部署v1.23.6版本的k8s原生集群，由于集群主要用于自己平时学习和测试使用，加上资源有限，暂不涉及高可用部署。 此前写的一些关于k8s基础知识和集群搭建的一些方案，有需要的同学可以看一下。">
<meta property="og:type" content="article">
<meta property="og:title" content="k8s系列04-kubeadm部署cilium网络的k8s集群">
<meta property="og:url" content="https://tinychen.com/20220510-k8s-04-deploy-k8s-with-cilium/index.html">
<meta property="og:site_name" content="TinyChen&#39;s Studio - 互联网技术学习工作经验分享">
<meta property="og:description" content="本文主要在centos7系统上基于docker和cilium组件部署v1.23.6版本的k8s原生集群，由于集群主要用于自己平时学习和测试使用，加上资源有限，暂不涉及高可用部署。 此前写的一些关于k8s基础知识和集群搭建的一些方案，有需要的同学可以看一下。">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://resource.tinychen.com/202205101809761.jpg">
<meta property="article:published_time" content="2022-05-10T05:00:00.000Z">
<meta property="article:modified_time" content="2022-05-10T05:00:00.000Z">
<meta property="article:author" content="TinyChen">
<meta property="article:tag" content="centos">
<meta property="article:tag" content="k8s">
<meta property="article:tag" content="docker">
<meta property="article:tag" content="cilium">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://resource.tinychen.com/202205101809761.jpg">
  
  
  <title>k8s系列04-kubeadm部署cilium网络的k8s集群 - TinyChen&#39;s Studio - 互联网技术学习工作经验分享</title>

  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4/github-markdown.min.css" />
  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hint.css@2/hint.min.css" />

  
    
    
      
      <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@10/styles/dracula.min.css" />
    
  

  
    <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3/dist/jquery.fancybox.min.css" />
  


<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->

  
<link rel="stylesheet" href="/css/fluid-extention.css">



  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    var CONFIG = {"hostname":"tinychen.com","root":"/","version":"1.8.14","typing":{"enable":true,"typeSpeed":30,"cursorChar":"_","loop":false},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"right","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"copy_btn":true,"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"baidu":"7a96963a1145ac7fde1442d739a11ffd","google":"UA-166769908-1","gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
<meta name="generator" content="Hexo 5.4.2"><link rel="alternate" href="/atom.xml" title="TinyChen's Studio - 互联网技术学习工作经验分享" type="application/atom+xml">
</head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>TinyChen</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                Home
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                Archives
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                Categories
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                Tags
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                About
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="banner" id="banner" parallax=true
         style="background: url('https://resource.tinychen.com/202205101808990.jpg') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="page-header text-center fade-in-up">
            <span class="h2" id="subtitle" title="k8s系列04-kubeadm部署cilium网络的k8s集群">
              
            </span>

            
              <div class="mt-3">
  
  
    <span class="post-meta">
      <i class="iconfont icon-date-fill" aria-hidden="true"></i>
      <time datetime="2022-05-10 13:00" pubdate>
        May 10, 2022 pm
      </time>
    </span>
  
</div>

<div class="mt-1">
  
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      36k 字
    </span>
  

  

  
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div class="py-5" id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">k8s系列04-kubeadm部署cilium网络的k8s集群</h1>
            
              <p class="note note-info">
                
                  本文最后更新于：May 10, 2022 pm
                
              </p>
            
            <div class="markdown-body">
              <p>本文主要在centos7系统上基于<code>docker</code>和<code>cilium</code>组件部署<code>v1.23.6</code>版本的k8s原生集群，由于集群主要用于自己平时学习和测试使用，加上资源有限，暂不涉及高可用部署。</p>
<p>此前写的一些关于k8s基础知识和集群搭建的一些<a href="https://tinychen.com/tags/k8s/">方案</a>，有需要的同学可以看一下。</p>
<span id="more"></span>

<h1 id="1、准备工作"><a href="#1、准备工作" class="headerlink" title="1、准备工作"></a>1、准备工作</h1><h2 id="1-1-cilium-集群节点信息"><a href="#1-1-cilium-集群节点信息" class="headerlink" title="1.1 cilium-集群节点信息"></a>1.1 cilium-集群节点信息</h2><p>机器均为8C8G的虚拟机，硬盘为100G。</p>
<table>
<thead>
<tr>
<th align="center">IP</th>
<th align="center">Hostname</th>
</tr>
</thead>
<tbody><tr>
<td align="center">10.31.188.1</td>
<td align="center">tiny-cilium-master-188-1.k8s.tcinternal</td>
</tr>
<tr>
<td align="center">10.31.188.11</td>
<td align="center">tiny-cilium-worker-188-11.k8s.tcinternal</td>
</tr>
<tr>
<td align="center">10.31.188.12</td>
<td align="center">tiny-cilium-worker-188-12.k8s.tcinternal</td>
</tr>
<tr>
<td align="center">10.188.0.0&#x2F;18</td>
<td align="center">serviceSubnet</td>
</tr>
</tbody></table>
<h2 id="1-2-检查mac和product-uuid"><a href="#1-2-检查mac和product-uuid" class="headerlink" title="1.2 检查mac和product_uuid"></a>1.2 检查mac和product_uuid</h2><p>同一个k8s集群内的所有节点需要确保<code>mac</code>地址和<code>product_uuid</code>均唯一，开始集群初始化之前需要检查相关信息</p>
<figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash"><span class="hljs-comment"># 检查mac地址</span><br>ip <span class="hljs-built_in">link</span> <br>ifconfig -a<br><br><span class="hljs-comment"># 检查product_uuid</span><br>sudo <span class="hljs-built_in">cat</span> /sys/class/dmi/id/product_uuid<br></code></pre></div></td></tr></table></figure>



<h2 id="1-3-配置ssh免密登录（可选）"><a href="#1-3-配置ssh免密登录（可选）" class="headerlink" title="1.3 配置ssh免密登录（可选）"></a>1.3 配置ssh免密登录（可选）</h2><p>如果k8s集群的节点有多个网卡，确保每个节点能通过正确的网卡互联访问</p>
<figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash"><span class="hljs-comment"># 在root用户下面生成一个公用的key，并配置可以使用该key免密登录</span><br>su root<br>ssh-keygen<br><span class="hljs-built_in">cd</span> /root/.ssh/<br><span class="hljs-built_in">cat</span> id_rsa.pub &gt;&gt; authorized_keys<br><span class="hljs-built_in">chmod</span> 600 authorized_keys<br><br><br><span class="hljs-built_in">cat</span> &gt;&gt; ~/.ssh/config &lt;&lt;<span class="hljs-string">EOF</span><br><span class="hljs-string">Host tiny-cilium-master-188-1.k8s.tcinternal</span><br><span class="hljs-string">    HostName 10.31.188.1</span><br><span class="hljs-string">    User root</span><br><span class="hljs-string">    Port 22</span><br><span class="hljs-string">    IdentityFile ~/.ssh/id_rsa</span><br><span class="hljs-string"></span><br><span class="hljs-string">Host tiny-cilium-worker-188-11.k8s.tcinternal</span><br><span class="hljs-string">    HostName 10.31.188.11</span><br><span class="hljs-string">    User root</span><br><span class="hljs-string">    Port 22</span><br><span class="hljs-string">    IdentityFile ~/.ssh/id_rsa</span><br><span class="hljs-string"></span><br><span class="hljs-string">Host tiny-cilium-worker-188-12.k8s.tcinternal</span><br><span class="hljs-string">    HostName 10.31.188.12</span><br><span class="hljs-string">    User root</span><br><span class="hljs-string">    Port 22</span><br><span class="hljs-string">    IdentityFile ~/.ssh/id_rsa</span><br><span class="hljs-string">EOF</span><br></code></pre></div></td></tr></table></figure>



<h2 id="1-4-修改hosts文件"><a href="#1-4-修改hosts文件" class="headerlink" title="1.4 修改hosts文件"></a>1.4 修改hosts文件</h2><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash"><span class="hljs-built_in">cat</span> &gt;&gt; /etc/hosts &lt;&lt;<span class="hljs-string">EOF</span><br><span class="hljs-string">10.31.188.1  tiny-cilium-master-188-1 tiny-cilium-master-188-1.k8s.tcinternal</span><br><span class="hljs-string">10.31.188.11 tiny-cilium-worker-188-11 tiny-cilium-worker-188-11.k8s.tcinternal</span><br><span class="hljs-string">10.31.188.12 tiny-cilium-worker-188-12 tiny-cilium-worker-188-12.k8s.tcinternal</span><br><span class="hljs-string">EOF</span><br></code></pre></div></td></tr></table></figure>



<h2 id="1-5-关闭swap内存"><a href="#1-5-关闭swap内存" class="headerlink" title="1.5 关闭swap内存"></a>1.5 关闭swap内存</h2><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash"><span class="hljs-comment"># 使用命令直接关闭swap内存</span><br>swapoff -a<br><span class="hljs-comment"># 修改fstab文件禁止开机自动挂载swap分区</span><br>sed -i <span class="hljs-string">&#x27;/swap / s/^\(.*\)$/#\1/g&#x27;</span> /etc/fstab<br></code></pre></div></td></tr></table></figure>



<h2 id="1-6-配置时间同步"><a href="#1-6-配置时间同步" class="headerlink" title="1.6 配置时间同步"></a>1.6 配置时间同步</h2><p>这里可以根据自己的习惯选择ntp或者是chrony同步均可，同步的时间源服务器可以选择阿里云的<code>ntp1.aliyun.com</code>或者是国家时间中心的<code>ntp.ntsc.ac.cn</code>。</p>
<h3 id="使用ntp同步"><a href="#使用ntp同步" class="headerlink" title="使用ntp同步"></a>使用ntp同步</h3><figure class="highlight cmake"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs cmake"><span class="hljs-comment"># 使用yum安装ntpdate工具</span><br>yum <span class="hljs-keyword">install</span> ntpdate -y<br><br><span class="hljs-comment"># 使用国家时间中心的源同步时间</span><br>ntpdate ntp.ntsc.ac.cn<br><br><span class="hljs-comment"># 最后查看一下时间</span><br>hwclock<br></code></pre></div></td></tr></table></figure>

<h3 id="使用chrony同步"><a href="#使用chrony同步" class="headerlink" title="使用chrony同步"></a>使用chrony同步</h3><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash"><span class="hljs-comment"># 使用yum安装chrony</span><br>yum install chrony -y<br><br><span class="hljs-comment"># 设置开机启动并开启chony并查看运行状态</span><br>systemctl <span class="hljs-built_in">enable</span> chronyd.service<br>systemctl start chronyd.service<br>systemctl status chronyd.service<br><br><span class="hljs-comment"># 当然也可以自定义时间服务器</span><br>vim /etc/chrony.conf<br><br><span class="hljs-comment"># 修改前</span><br>$ grep server /etc/chrony.conf<br><span class="hljs-comment"># Use public servers from the pool.ntp.org project.</span><br>server 0.centos.pool.ntp.org iburst<br>server 1.centos.pool.ntp.org iburst<br>server 2.centos.pool.ntp.org iburst<br>server 3.centos.pool.ntp.org iburst<br><br><span class="hljs-comment"># 修改后</span><br>$ grep server /etc/chrony.conf<br><span class="hljs-comment"># Use public servers from the pool.ntp.org project.</span><br>server ntp.ntsc.ac.cn iburst<br><br><span class="hljs-comment"># 重启服务使配置文件生效</span><br>systemctl restart chronyd.service<br><br><span class="hljs-comment"># 查看chrony的ntp服务器状态</span><br>chronyc sourcestats -v<br>chronyc sources -v<br><br></code></pre></div></td></tr></table></figure>



<h2 id="1-7-关闭selinux"><a href="#1-7-关闭selinux" class="headerlink" title="1.7 关闭selinux"></a>1.7 关闭selinux</h2><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash"><span class="hljs-comment"># 使用命令直接关闭</span><br>setenforce 0<br><br><span class="hljs-comment"># 也可以直接修改/etc/selinux/config文件</span><br>sed -i <span class="hljs-string">&#x27;s/^SELINUX=enforcing$/SELINUX=disabled/&#x27;</span> /etc/selinux/config<br></code></pre></div></td></tr></table></figure>



<h2 id="1-8-配置防火墙"><a href="#1-8-配置防火墙" class="headerlink" title="1.8 配置防火墙"></a>1.8 配置防火墙</h2><p>k8s集群之间通信和服务暴露需要使用较多端口，为了方便，直接禁用防火墙</p>
<figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash"><span class="hljs-comment"># centos7使用systemctl禁用默认的firewalld服务</span><br>systemctl <span class="hljs-built_in">disable</span> firewalld.service<br></code></pre></div></td></tr></table></figure>



<h2 id="1-9-配置netfilter参数"><a href="#1-9-配置netfilter参数" class="headerlink" title="1.9 配置netfilter参数"></a>1.9 配置netfilter参数</h2><p>这里主要是需要配置内核加载<code>br_netfilter</code>和<code>iptables</code>放行<code>ipv6</code>和<code>ipv4</code>的流量，确保集群内的容器能够正常通信。</p>
<figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash"><span class="hljs-built_in">cat</span> &lt;&lt;<span class="hljs-string">EOF | sudo tee /etc/modules-load.d/k8s.conf</span><br><span class="hljs-string">br_netfilter</span><br><span class="hljs-string">EOF</span><br><br><span class="hljs-built_in">cat</span> &lt;&lt;<span class="hljs-string">EOF | sudo tee /etc/sysctl.d/k8s.conf</span><br><span class="hljs-string">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="hljs-string">net.bridge.bridge-nf-call-iptables = 1</span><br><span class="hljs-string">EOF</span><br>sudo sysctl --system<br></code></pre></div></td></tr></table></figure>



<h2 id="1-10-关闭IPV6（不建议）"><a href="#1-10-关闭IPV6（不建议）" class="headerlink" title="1.10 关闭IPV6（不建议）"></a>1.10 关闭IPV6（不建议）</h2><p>和之前部署其他的CNI不一样，cilium很多服务监听默认情况下都是双栈的（使用cilium-cli操作的时候），因此建议开启系统的IPV6网络支持（即使没有可用的IPV6路由也可以）</p>
<p>当然没有ipv6网络也是可以的，只是在使用cilium-cli的一些开启port-forward命令时会报错而已。</p>
<figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash"><span class="hljs-comment"># 直接在内核中添加ipv6禁用参数</span><br>grubby --update-kernel=ALL --args=ipv6.disable=1<br></code></pre></div></td></tr></table></figure>

<h2 id="1-11-配置IPVS（建议）"><a href="#1-11-配置IPVS（建议）" class="headerlink" title="1.11 配置IPVS（建议）"></a>1.11 配置IPVS（建议）</h2><p>IPVS是专门设计用来应对负载均衡场景的组件，<a target="_blank" rel="noopener" href="https://github.com/kubernetes/kubernetes/blob/master/pkg/proxy/ipvs/README.md#run-kube-proxy-in-ipvs-mode">kube-proxy 中的 IPVS 实现</a>通过减少对 iptables 的使用来增加可扩展性。在 iptables 输入链中不使用 PREROUTING，而是创建一个假的接口，叫做 kube-ipvs0，当k8s集群中的负载均衡配置变多的时候，IPVS能实现比iptables更高效的转发性能。</p>
<blockquote>
<p>因为cilium需要升级系统内核，因此这里的内核版本高于4.19</p>
<p>注意在4.19之后的内核版本中使用<code>nf_conntrack</code>模块来替换了原有的<code>nf_conntrack_ipv4</code>模块</p>
<p>(<strong>Notes</strong>: use <code>nf_conntrack</code> instead of <code>nf_conntrack_ipv4</code> for Linux kernel 4.19 and later)</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash"><span class="hljs-comment"># 在使用ipvs模式之前确保安装了ipset和ipvsadm</span><br>sudo yum install ipset ipvsadm -y<br><br><span class="hljs-comment"># 手动加载ipvs相关模块</span><br>modprobe -- ip_vs<br>modprobe -- ip_vs_rr<br>modprobe -- ip_vs_wrr<br>modprobe -- ip_vs_sh<br>modprobe -- nf_conntrack<br><br><span class="hljs-comment"># 配置开机自动加载ipvs相关模块</span><br><span class="hljs-built_in">cat</span> &lt;&lt;<span class="hljs-string">EOF | sudo tee /etc/modules-load.d/ipvs.conf</span><br><span class="hljs-string">ip_vs</span><br><span class="hljs-string">ip_vs_rr</span><br><span class="hljs-string">ip_vs_wrr</span><br><span class="hljs-string">ip_vs_sh</span><br><span class="hljs-string">nf_conntrack</span><br><span class="hljs-string">EOF</span><br><br>sudo sysctl --system<br><span class="hljs-comment"># 最好重启一遍系统确定是否生效</span><br><br>$ lsmod | grep -e ip_vs -e nf_conntrack<br>nf_conntrack_netlink    49152  0<br>nfnetlink              20480  2 nf_conntrack_netlink<br>ip_vs_sh               16384  0<br>ip_vs_wrr              16384  0<br>ip_vs_rr               16384  0<br>ip_vs                 159744  6 ip_vs_rr,ip_vs_sh,ip_vs_wrr<br>nf_conntrack          159744  5 xt_conntrack,nf_nat,nf_conntrack_netlink,xt_MASQUERADE,ip_vs<br>nf_defrag_ipv4         16384  1 nf_conntrack<br>nf_defrag_ipv6         24576  2 nf_conntrack,ip_vs<br>libcrc32c              16384  4 nf_conntrack,nf_nat,xfs,ip_vs<br>$ <span class="hljs-built_in">cut</span> -f1 -d <span class="hljs-string">&quot; &quot;</span>  /proc/modules | grep -e ip_vs -e nf_conntrack<br>nf_conntrack_netlink<br>ip_vs_sh<br>ip_vs_wrr<br>ip_vs_rr<br>ip_vs<br>nf_conntrack<br></code></pre></div></td></tr></table></figure>

<h2 id="1-12-配置Linux内核（cilium必选）"><a href="#1-12-配置Linux内核（cilium必选）" class="headerlink" title="1.12 配置Linux内核（cilium必选）"></a>1.12 配置Linux内核（cilium必选）</h2><p>cilium和其他的cni组件最大的不同在于其底层使用了ebpf技术，而该技术对于Linux的系统内核版本有较高的要求，完成的要求可以查看官网的<a target="_blank" rel="noopener" href="https://docs.cilium.io/en/latest/operations/system_requirements/">详细链接</a>，这里我们着重看内核版本、内核参数这两个部分。</p>
<h3 id="Linux内核版本"><a href="#Linux内核版本" class="headerlink" title="Linux内核版本"></a>Linux内核版本</h3><p>默认情况下我们可以参考cilium官方给出的一个系统要求总结。因为我们是在k8s集群中部署（使用容器），因此只需要关注Linux内核版本和etcd版本即可。根据前面部署的经验我们可以知道1.23.6版本的k8s默认使用的etcd版本是<code>3.5.+</code>，因此重点就来到了Linux内核版本这里。</p>
<table>
<thead>
<tr>
<th>Requirement</th>
<th>Minimum Version</th>
<th>In cilium container</th>
</tr>
</thead>
<tbody><tr>
<td><a target="_blank" rel="noopener" href="https://docs.cilium.io/en/latest/operations/system_requirements/#linux-kernel">Linux kernel</a></td>
<td>&gt;&#x3D; 4.9.17</td>
<td>no</td>
</tr>
<tr>
<td>Key-Value store (etcd)</td>
<td>&gt;&#x3D; 3.1.0</td>
<td>no</td>
</tr>
<tr>
<td>clang+LLVM</td>
<td>&gt;&#x3D; 10.0</td>
<td>yes</td>
</tr>
<tr>
<td>iproute2</td>
<td>&gt;&#x3D; 5.9.0</td>
<td>yes</td>
</tr>
</tbody></table>
<blockquote>
<p>This requirement is only needed if you run <code>cilium-agent</code> natively. If you are using the Cilium container image <code>cilium/cilium</code>, clang+LLVM is included in the container image.</p>
<p>iproute2 is only needed if you run <code>cilium-agent</code> directly on the host machine. iproute2 is included in the <code>cilium/cilium</code> container image.</p>
</blockquote>
<p>毫无疑问CentOS7内置的默认内核版本3.10.x版本的内核是无法满足需求的，但是在升级内核之前，我们再看看其他的一些要求。</p>
<p>cilium官方还给出了<a target="_blank" rel="noopener" href="https://docs.cilium.io/en/latest/operations/system_requirements/#required-kernel-versions-for-advanced-features">一份列表</a>描述了各项高级功能对内核版本的要求：</p>
<table>
<thead>
<tr>
<th>Cilium Feature</th>
<th>Minimum Kernel Version</th>
</tr>
</thead>
<tbody><tr>
<td><a target="_blank" rel="noopener" href="https://docs.cilium.io/en/latest/concepts/networking/fragmentation/#concepts-fragmentation">IPv4 fragment handling</a></td>
<td>&gt;&#x3D; 4.10</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://docs.cilium.io/en/latest/operations/upgrade/#cidr-limitations">Restrictions on unique prefix lengths for CIDR policy rules</a></td>
<td>&gt;&#x3D; 4.11</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://docs.cilium.io/en/latest/gettingstarted/encryption-ipsec/#encryption-ipsec">IPsec Transparent Encryption</a> in tunneling mode</td>
<td>&gt;&#x3D; 4.19</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://docs.cilium.io/en/latest/gettingstarted/encryption-wireguard/#encryption-wg">WireGuard Transparent Encryption</a></td>
<td>&gt;&#x3D; 5.6</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://docs.cilium.io/en/latest/gettingstarted/host-services/#host-services">Host-Reachable Services</a></td>
<td>&gt;&#x3D; 4.19.57, &gt;&#x3D; 5.1.16, &gt;&#x3D; 5.2</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://docs.cilium.io/en/latest/gettingstarted/kubeproxy-free/#kubeproxy-free">Kubernetes Without kube-proxy</a></td>
<td>&gt;&#x3D; 4.19.57, &gt;&#x3D; 5.1.16, &gt;&#x3D; 5.2</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://docs.cilium.io/en/latest/gettingstarted/bandwidth-manager/#bandwidth-manager">Bandwidth Manager</a></td>
<td>&gt;&#x3D; 5.1</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://docs.cilium.io/en/latest/gettingstarted/local-redirect-policy/#local-redirect-policy">Local Redirect Policy (beta)</a></td>
<td>&gt;&#x3D; 4.19.57, &gt;&#x3D; 5.1.16, &gt;&#x3D; 5.2</td>
</tr>
<tr>
<td>Full support for <a target="_blank" rel="noopener" href="https://docs.cilium.io/en/latest/gettingstarted/kubeproxy-free/#session-affinity">Session Affinity</a></td>
<td>&gt;&#x3D; 5.7</td>
</tr>
<tr>
<td>BPF-based proxy redirection</td>
<td>&gt;&#x3D; 5.7</td>
</tr>
<tr>
<td>BPF-based host routing</td>
<td>&gt;&#x3D; 5.10</td>
</tr>
<tr>
<td>Socket-level LB bypass in pod netns</td>
<td>&gt;&#x3D; 5.7</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://docs.cilium.io/en/latest/gettingstarted/egress-gateway/#egress-gateway">Egress Gateway (beta)</a></td>
<td>&gt;&#x3D; 5.2</td>
</tr>
<tr>
<td>VXLAN Tunnel Endpoint (VTEP) Integration</td>
<td>&gt;&#x3D; 5.2</td>
</tr>
</tbody></table>
<p>可以看到如果需要满足上面所有需求的话，需要内核版本高于5.10，本着学习测试研究作死的精神，反正都升级了，干脆就升级到新一些的版本吧。这里我们可以直接<a href="https://tinychen.com/20190612-centos-update-kernel/">使用elrepo源来升级内核</a>到较新的内核版本。</p>
<figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash"><span class="hljs-comment"># 查看elrepo源中支持的内核版本</span><br>$ yum --disablerepo=<span class="hljs-string">&quot;*&quot;</span> --enablerepo=<span class="hljs-string">&quot;elrepo-kernel&quot;</span> list available<br>Loaded plugins: fastestmirror<br>Loading mirror speeds from cached hostfile<br>Available Packages<br>elrepo-release.noarch                                                                   7.0-5.el7.elrepo                                                           elrepo-kernel<br>kernel-lt.x86_64                                                                        5.4.192-1.el7.elrepo                                                       elrepo-kernel<br>kernel-lt-devel.x86_64                                                                  5.4.192-1.el7.elrepo                                                       elrepo-kernel<br>kernel-lt-doc.noarch                                                                    5.4.192-1.el7.elrepo                                                       elrepo-kernel<br>kernel-lt-headers.x86_64                                                                5.4.192-1.el7.elrepo                                                       elrepo-kernel<br>kernel-lt-tools.x86_64                                                                  5.4.192-1.el7.elrepo                                                       elrepo-kernel<br>kernel-lt-tools-libs.x86_64                                                             5.4.192-1.el7.elrepo                                                       elrepo-kernel<br>kernel-lt-tools-libs-devel.x86_64                                                       5.4.192-1.el7.elrepo                                                       elrepo-kernel<br>kernel-ml.x86_64                                                                        5.17.6-1.el7.elrepo                                                        elrepo-kernel<br>kernel-ml-devel.x86_64                                                                  5.17.6-1.el7.elrepo                                                        elrepo-kernel<br>kernel-ml-doc.noarch                                                                    5.17.6-1.el7.elrepo                                                        elrepo-kernel<br>kernel-ml-headers.x86_64                                                                5.17.6-1.el7.elrepo                                                        elrepo-kernel<br>kernel-ml-tools.x86_64                                                                  5.17.6-1.el7.elrepo                                                        elrepo-kernel<br>kernel-ml-tools-libs.x86_64                                                             5.17.6-1.el7.elrepo                                                        elrepo-kernel<br>kernel-ml-tools-libs-devel.x86_64                                                       5.17.6-1.el7.elrepo                                                        elrepo-kernel<br>perf.x86_64                                                                             5.17.6-1.el7.elrepo                                                        elrepo-kernel<br>python-perf.x86_64                                                                      5.17.6-1.el7.elrepo                                                        elrepo-kernel<br><br><span class="hljs-comment"># 看起来ml版本的内核比较满足我们的需求,直接使用yum进行安装</span><br>sudo yum --enablerepo=elrepo-kernel install kernel-ml -y<br><span class="hljs-comment"># 使用grubby工具查看系统中已经安装的内核版本信息</span><br>sudo grubby --info=ALL<br><span class="hljs-comment"># 设置新安装的5.17.6版本内核为默认内核版本，此处的index=0要和上面查看的内核版本信息一致</span><br>sudo grubby --set-default-index=0<br><span class="hljs-comment"># 查看默认内核是否修改成功</span><br>sudo grubby --default-kernel<br><span class="hljs-comment"># 重启系统切换到新内核</span><br>init 6<br><span class="hljs-comment"># 重启后检查内核版本是否为新的5.17.6</span><br><span class="hljs-built_in">uname</span> -a<br></code></pre></div></td></tr></table></figure>

<h3 id="Linux内核参数"><a href="#Linux内核参数" class="headerlink" title="Linux内核参数"></a>Linux内核参数</h3><p>首先我们查看自己当前内核版本的参数，基本上可以分为<code>y</code>、<code>n</code>、<code>m</code>三个选项</p>
<ul>
<li>y：yes，Build directly into the kernel. 表示该功能被编译进内核中，默认启用</li>
<li>n：no，Leave entirely out of the kernel. 表示该功能未被编译进内核中，不启用</li>
<li>m：module，Build as a module, to be loaded if needed. 表示该功能被编译为模块，按需启用</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash"><span class="hljs-comment"># 查看当前使用的内核版本的编译参数</span><br><span class="hljs-built_in">cat</span> /boot/config-$(<span class="hljs-built_in">uname</span> -r)<br></code></pre></div></td></tr></table></figure>

<p>cilium官方对各项功能所需要开启的<a target="_blank" rel="noopener" href="https://docs.cilium.io/en/latest/operations/system_requirements/#linux-kernel">内核参数列举</a>如下：</p>
<blockquote>
<p>In order for the eBPF feature to be enabled properly, the following kernel configuration options must be enabled. This is typically the case with distribution kernels. When an option can be built as a module or statically linked, either choice is valid.</p>
<p>为了正确启用 eBPF 功能，必须启用以下内核配置选项。这通常因内核版本情况而异。任何一个选项都可以构建为模块或静态链接，两个选择都是有效的。</p>
</blockquote>
<p>我们暂时只看最基本的<code>Base Requirements</code></p>
<figure class="highlight ini"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs ini"><span class="hljs-attr">CONFIG_BPF</span>=y<br><span class="hljs-attr">CONFIG_BPF_SYSCALL</span>=y<br><span class="hljs-attr">CONFIG_NET_CLS_BPF</span>=y<br><span class="hljs-attr">CONFIG_BPF_JIT</span>=y<br><span class="hljs-attr">CONFIG_NET_CLS_ACT</span>=y<br><span class="hljs-attr">CONFIG_NET_SCH_INGRESS</span>=y<br><span class="hljs-attr">CONFIG_CRYPTO_SHA1</span>=y<br><span class="hljs-attr">CONFIG_CRYPTO_USER_API_HASH</span>=y<br><span class="hljs-attr">CONFIG_CGROUPS</span>=y<br><span class="hljs-attr">CONFIG_CGROUP_BPF</span>=y<br></code></pre></div></td></tr></table></figure>

<p>对比我们使用的<code>5.17.6-1.el7.elrepo.x86_64</code>内核可以发现有两个模块是为m</p>
<figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ egrep <span class="hljs-string">&quot;^CONFIG_BPF=|^CONFIG_BPF_SYSCALL=|^CONFIG_NET_CLS_BPF=|^CONFIG_BPF_JIT=|^CONFIG_NET_CLS_ACT=|^CONFIG_NET_SCH_INGRESS=|^CONFIG_CRYPTO_SHA1=|^CONFIG_CRYPTO_USER_API_HASH=|^CONFIG_CGROUPS=|^CONFIG_CGROUP_BPF=&quot;</span> /boot/config-5.17.6-1.el7.elrepo.x86_64<br>CONFIG_BPF=y<br>CONFIG_BPF_SYSCALL=y<br>CONFIG_BPF_JIT=y<br>CONFIG_CGROUPS=y<br>CONFIG_CGROUP_BPF=y<br>CONFIG_NET_SCH_INGRESS=m<br>CONFIG_NET_CLS_BPF=m<br>CONFIG_NET_CLS_ACT=y<br>CONFIG_CRYPTO_SHA1=y<br>CONFIG_CRYPTO_USER_API_HASH=y<br></code></pre></div></td></tr></table></figure>

<p>缺少的这两个模块我们可以在<code>/usr/lib/modules/$(uname -r)</code>目录下面找到它们：</p>
<figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ <span class="hljs-built_in">realpath</span> ./kernel/net/sched/sch_ingress.ko<br>/usr/lib/modules/5.17.6-1.el7.elrepo.x86_64/kernel/net/sched/sch_ingress.ko<br>$ <span class="hljs-built_in">realpath</span> ./kernel/net/sched/cls_bpf.ko<br>/usr/lib/modules/5.17.6-1.el7.elrepo.x86_64/kernel/net/sched/cls_bpf.ko<br></code></pre></div></td></tr></table></figure>

<p>确认相关内核模块存在我们直接加载内核即可：</p>
<figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash"><span class="hljs-comment"># 直接使用modprobe命令加载</span><br>$ modprobe cls_bpf<br>$ modprobe sch_ingress<br>$ lsmod | egrep <span class="hljs-string">&quot;cls_bpf|sch_ingress&quot;</span><br>sch_ingress            16384  0<br>cls_bpf                24576  0<br><br><span class="hljs-comment"># 配置开机自动加载cilium所需相关模块</span><br><span class="hljs-built_in">cat</span> &lt;&lt;<span class="hljs-string">EOF | sudo tee /etc/modules-load.d/cilium-base-requirements.conf</span><br><span class="hljs-string">cls_bpf</span><br><span class="hljs-string">sch_ingress</span><br><span class="hljs-string">EOF</span><br></code></pre></div></td></tr></table></figure>

<p>其他cilium高级功能所需要的内核功能也类似，这里不做赘述。</p>
<h1 id="2、安装container-runtime"><a href="#2、安装container-runtime" class="headerlink" title="2、安装container runtime"></a>2、安装container runtime</h1><h2 id="2-1-安装docker"><a href="#2-1-安装docker" class="headerlink" title="2.1 安装docker"></a>2.1 安装docker</h2><p>详细的官方文档可以参考<a target="_blank" rel="noopener" href="https://kubernetes.io/docs/setup/production-environment/container-runtimes/">这里</a>，由于在刚发布的1.24版本中移除了<code>docker-shim</code>，因此安装的<code>版本≥1.24</code>的时候需要注意<code>容器运行时</code>的选择。这里我们安装的版本低于1.24，因此我们继续使用docker。</p>
<p>docker的具体安装可以参考我之前写的<a href="https://tinychen.com/20190912-centos-install-docker/">这篇文章</a>，这里不做赘述。</p>
<figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash"><span class="hljs-comment"># 安装必要的依赖组件并且导入docker官方提供的yum源</span><br>sudo yum install -y yum-utils device-mapper-persistent-data lvm2<br>sudo yum-config-manager --add-repo  https://download.docker.com/linux/centos/docker-ce.repo<br><br><span class="hljs-comment"># 我们直接安装最新版本的docker</span><br>yum install docker-ce docker-ce-cli containerd.io<br></code></pre></div></td></tr></table></figure>

<h2 id="2-2-配置cgroup-drivers"><a href="#2-2-配置cgroup-drivers" class="headerlink" title="2.2 配置cgroup drivers"></a>2.2 配置cgroup drivers</h2><p>CentOS7使用的是<code>systemd</code>来初始化系统并管理进程，初始化进程会生成并使用一个 root 控制组 (<code>cgroup</code>), 并充当 <code>cgroup</code> 管理器。 <code>Systemd</code> 与 <code>cgroup</code> 集成紧密，并将为每个 <code>systemd</code> 单元分配一个 <code>cgroup</code>。 我们也可以配置<code>容器运行时</code>和 <code>kubelet</code> 使用 <code>cgroupfs</code>。 连同 <code>systemd</code> 一起使用 <code>cgroupfs</code> 意味着将有两个不同的 <code>cgroup 管理器</code>。而当一个系统中同时存在cgroupfs和systemd两者时，容易变得不稳定，因此最好更改设置，令容器运行时和 kubelet 使用 <code>systemd</code> 作为 <code>cgroup</code> 驱动，以此使系统更为稳定。 对于 Docker, 需要设置 <code>native.cgroupdriver=systemd</code> 参数。</p>
<blockquote>
<p>参考官方的说明文档：</p>
<p><a target="_blank" rel="noopener" href="https://kubernetes.io/docs/setup/production-environment/container-runtimes/#cgroup-drivers">https://kubernetes.io/docs/setup/production-environment/container-runtimes/#cgroup-drivers</a></p>
<p>参考配置说明文档</p>
<p><a target="_blank" rel="noopener" href="https://kubernetes.io/zh/docs/setup/production-environment/container-runtimes/#docker">https://kubernetes.io/zh/docs/setup/production-environment/container-runtimes/#docker</a></p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">sudo <span class="hljs-built_in">mkdir</span> /etc/docker<br><span class="hljs-built_in">cat</span> &lt;&lt;<span class="hljs-string">EOF | sudo tee /etc/docker/daemon.json</span><br><span class="hljs-string">&#123;</span><br><span class="hljs-string">  &quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;],</span><br><span class="hljs-string">  &quot;log-driver&quot;: &quot;json-file&quot;,</span><br><span class="hljs-string">  &quot;log-opts&quot;: &#123;</span><br><span class="hljs-string">    &quot;max-size&quot;: &quot;100m&quot;</span><br><span class="hljs-string">  &#125;,</span><br><span class="hljs-string">  &quot;storage-driver&quot;: &quot;overlay2&quot;</span><br><span class="hljs-string">&#125;</span><br><span class="hljs-string">EOF</span><br><br>sudo systemctl <span class="hljs-built_in">enable</span> docker<br>sudo systemctl daemon-reload<br>sudo systemctl restart docker<br><br><br><span class="hljs-comment"># 最后检查一下Cgroup Driver是否为systemd</span><br>$ docker info | grep systemd<br> Cgroup Driver: systemd<br></code></pre></div></td></tr></table></figure>

<h2 id="2-3-关于kubelet的cgroup-driver"><a href="#2-3-关于kubelet的cgroup-driver" class="headerlink" title="2.3 关于kubelet的cgroup driver"></a>2.3 关于kubelet的cgroup driver</h2><p>k8s官方有<a target="_blank" rel="noopener" href="https://kubernetes.io/docs/tasks/administer-cluster/kubeadm/configure-cgroup-driver/">详细的文档</a>介绍了如何设置kubelet的<code>cgroup driver</code>，需要特别注意的是，在1.22版本开始，如果没有手动设置kubelet的cgroup driver，那么默认会设置为systemd</p>
<blockquote>
<p><strong>Note:</strong> In v1.22, if the user is not setting the <code>cgroupDriver</code> field under <code>KubeletConfiguration</code>, <code>kubeadm</code> will default it to <code>systemd</code>.</p>
</blockquote>
<p>一个比较简单的指定kubelet的<code>cgroup driver</code>的方法就是在<code>kubeadm-config.yaml</code>加入<code>cgroupDriver</code>字段</p>
<figure class="highlight yaml"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs yaml"><span class="hljs-comment"># kubeadm-config.yaml</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">ClusterConfiguration</span><br><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">kubeadm.k8s.io/v1beta3</span><br><span class="hljs-attr">kubernetesVersion:</span> <span class="hljs-string">v1.21.0</span><br><span class="hljs-meta">---</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">KubeletConfiguration</span><br><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">kubelet.config.k8s.io/v1beta1</span><br><span class="hljs-attr">cgroupDriver:</span> <span class="hljs-string">systemd</span><br></code></pre></div></td></tr></table></figure>

<p>我们可以直接查看configmaps来查看初始化之后集群的kubeadm-config配置。</p>
<figure class="highlight asciidoc"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs asciidoc">$ kubectl describe configmaps kubeadm-config -n kube-system<br>Name:         kubeadm-config<br>Namespace:    kube-system<br>Labels:       &lt;none&gt;<br>Annotations:  &lt;none&gt;<br><br><span class="hljs-section">Data</span><br><span class="hljs-section">====</span><br><span class="hljs-section">ClusterConfiguration:</span><br><span class="hljs-section">----</span><br>apiServer:<br><span class="hljs-code">  extraArgs:</span><br><span class="hljs-code">    authorization-mode: Node,RBAC</span><br><span class="hljs-code">  timeoutForControlPlane: 4m0s</span><br>apiVersion: kubeadm.k8s.io/v1beta3<br>certificatesDir: /etc/kubernetes/pki<br>clusterName: kubernetes<br>controllerManager: &#123;&#125;<br>dns: &#123;&#125;<br>etcd:<br><span class="hljs-code">  local:</span><br><span class="hljs-code">    dataDir: /var/lib/etcd</span><br>imageRepository: registry.aliyuncs.com/google_containers<br>kind: ClusterConfiguration<br>kubernetesVersion: v1.23.6<br>networking:<br><span class="hljs-code">  dnsDomain: cali-cluster.tclocal</span><br><span class="hljs-code">  serviceSubnet: 10.88.0.0/18</span><br>scheduler: &#123;&#125;<br><br><br><span class="hljs-section">BinaryData</span><br><span class="hljs-section">====</span><br><br>Events:  &lt;none&gt;<br></code></pre></div></td></tr></table></figure>

<p>当然因为我们需要安装的版本高于1.22.0并且使用的就是systemd，因此可以不用再重复配置。</p>
<h1 id="3、安装kube三件套"><a href="#3、安装kube三件套" class="headerlink" title="3、安装kube三件套"></a>3、安装kube三件套</h1><blockquote>
<p>对应的官方文档可以参考这里</p>
<p><a target="_blank" rel="noopener" href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/#installing-kubeadm-kubelet-and-kubectl">https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/#installing-kubeadm-kubelet-and-kubectl</a></p>
</blockquote>
<p>kube三件套就是<code>kubeadm</code>、<code>kubelet</code> 和 <code>kubectl</code>，三者的具体功能和作用如下：</p>
<ul>
<li><code>kubeadm</code>：用来初始化集群的指令。</li>
<li><code>kubelet</code>：在集群中的每个节点上用来启动 Pod 和容器等。</li>
<li><code>kubectl</code>：用来与集群通信的命令行工具。</li>
</ul>
<p>需要注意的是：</p>
<ul>
<li><code>kubeadm</code>不会帮助我们管理<code>kubelet</code>和<code>kubectl</code>，其他两者也是一样的，也就是说这三者是相互独立的，并不存在谁管理谁的情况；</li>
<li><code>kubelet</code>的版本必须小于等于<code>API-server</code>的版本，否则容易出现兼容性的问题；</li>
<li><code>kubectl</code>并不是集群中的每个节点都需要安装，也并不是一定要安装在集群中的节点，可以单独安装在自己本地的机器环境上面，然后配合<code>kubeconfig</code>文件即可使用<code>kubectl</code>命令来远程管理对应的k8s集群；</li>
</ul>
<p>CentOS7的安装比较简单，我们直接使用官方提供的<code>yum</code>源即可。需要注意的是这里需要设置<code>selinux</code>的状态，但是前面我们已经关闭了selinux，因此这里略过这步。</p>
<figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash"><span class="hljs-comment"># 直接导入谷歌官方的yum源</span><br><span class="hljs-built_in">cat</span> &lt;&lt;<span class="hljs-string">EOF | sudo tee /etc/yum.repos.d/kubernetes.repo</span><br><span class="hljs-string">[kubernetes]</span><br><span class="hljs-string">name=Kubernetes</span><br><span class="hljs-string">baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-\$basearch</span><br><span class="hljs-string">enabled=1</span><br><span class="hljs-string">gpgcheck=1</span><br><span class="hljs-string">repo_gpgcheck=1</span><br><span class="hljs-string">gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg</span><br><span class="hljs-string">exclude=kubelet kubeadm kubectl</span><br><span class="hljs-string">EOF</span><br><br><span class="hljs-comment"># 当然如果连不上谷歌的源，可以考虑使用国内的阿里镜像源</span><br><span class="hljs-built_in">cat</span> &lt;&lt;<span class="hljs-string">EOF &gt; /etc/yum.repos.d/kubernetes.repo</span><br><span class="hljs-string">[kubernetes]</span><br><span class="hljs-string">name=Kubernetes</span><br><span class="hljs-string">baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/</span><br><span class="hljs-string">enabled=1</span><br><span class="hljs-string">gpgcheck=1</span><br><span class="hljs-string">repo_gpgcheck=1</span><br><span class="hljs-string">gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg</span><br><span class="hljs-string">EOF</span><br><br><br><span class="hljs-comment"># 接下来直接安装三件套即可</span><br>sudo yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes<br><br><span class="hljs-comment"># 如果网络环境不好出现gpgcheck验证失败导致无法正常读取yum源，可以考虑关闭该yum源的repo_gpgcheck</span><br>sed -i <span class="hljs-string">&#x27;s/repo_gpgcheck=1/repo_gpgcheck=0/g&#x27;</span> /etc/yum.repos.d/kubernetes.repo<br><span class="hljs-comment"># 或者在安装的时候禁用gpgcheck</span><br>sudo yum install -y kubelet kubeadm kubectl --nogpgcheck --disableexcludes=kubernetes<br><br><br><br><span class="hljs-comment"># 如果想要安装特定版本，可以使用这个命令查看相关版本的信息</span><br>sudo yum list --nogpgcheck kubelet kubeadm kubectl --showduplicates --disableexcludes=kubernetes<br><span class="hljs-comment"># 这里我们为了保留使用docker-shim，因此我们按照1.24.0版本的前一个版本1.23.6</span><br>sudo yum install -y kubelet-1.23.6-0 kubeadm-1.23.6-0 kubectl-1.23.6-0 --nogpgcheck --disableexcludes=kubernetes<br><br><span class="hljs-comment"># 安装完成后配置开机自启kubelet</span><br>sudo systemctl <span class="hljs-built_in">enable</span> --now kubelet<br></code></pre></div></td></tr></table></figure>

<h1 id="4、初始化集群"><a href="#4、初始化集群" class="headerlink" title="4、初始化集群"></a>4、初始化集群</h1><h2 id="4-1-编写配置文件"><a href="#4-1-编写配置文件" class="headerlink" title="4.1 编写配置文件"></a>4.1 编写配置文件</h2><p>在集群中所有节点都执行完上面的三点操作之后，我们就可以开始创建k8s集群了。因为我们这次不涉及高可用部署，因此初始化的时候直接在我们的目标master节点上面操作即可。</p>
<figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash"><span class="hljs-comment"># 我们先使用kubeadm命令查看一下主要的几个镜像版本</span><br><span class="hljs-comment"># 因为我们此前指定安装了旧的1.23.6版本，这里的apiserver镜像版本也会随之回滚</span><br>$ kubeadm config images list<br>I0509 12:06:03.036544    3593 version.go:255] remote version is much newer: v1.24.0; falling back to: stable-1.23<br>k8s.gcr.io/kube-apiserver:v1.23.6<br>k8s.gcr.io/kube-controller-manager:v1.23.6<br>k8s.gcr.io/kube-scheduler:v1.23.6<br>k8s.gcr.io/kube-proxy:v1.23.6<br>k8s.gcr.io/pause:3.6<br>k8s.gcr.io/etcd:3.5.1-0<br>k8s.gcr.io/coredns/coredns:v1.8.6<br><br><span class="hljs-comment"># 为了方便编辑和管理，我们还是把初始化参数导出成配置文件</span><br>$ kubeadm config <span class="hljs-built_in">print</span> init-defaults &gt; kubeadm-cilium.conf<br><br></code></pre></div></td></tr></table></figure>

<ul>
<li>考虑到大多数情况下国内的网络无法使用谷歌的k8s.gcr.io镜像源，我们可以直接在配置文件中修改<code>imageRepository</code>参数为阿里的镜像源</li>
<li><code>kubernetesVersion</code>字段用来指定我们要安装的k8s版本</li>
<li><code>localAPIEndpoint</code>参数需要修改为我们的master节点的IP和端口，初始化之后的k8s集群的apiserver地址就是这个</li>
<li><code>podSubnet</code>、<code>serviceSubnet</code>和<code>dnsDomain</code>两个参数默认情况下可以不用修改，这里我按照自己的需求进行了变更</li>
<li><code>nodeRegistration</code>里面的<code>name</code>参数修改为对应master节点的<code>hostname</code></li>
<li>新增配置块使用ipvs，具体可以参考<a target="_blank" rel="noopener" href="https://github.com/kubernetes/kubernetes/blob/master/pkg/proxy/ipvs/README.md#cluster-created-by-kubeadm">官方文档</a></li>
</ul>
<figure class="highlight yaml"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs yaml"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">kubeadm.k8s.io/v1beta3</span><br><span class="hljs-attr">bootstrapTokens:</span><br><span class="hljs-bullet">-</span> <span class="hljs-attr">groups:</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-string">system:bootstrappers:kubeadm:default-node-token</span><br>  <span class="hljs-attr">token:</span> <span class="hljs-string">abcdef.0123456789abcdef</span><br>  <span class="hljs-attr">ttl:</span> <span class="hljs-string">24h0m0s</span><br>  <span class="hljs-attr">usages:</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-string">signing</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-string">authentication</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">InitConfiguration</span><br><span class="hljs-attr">localAPIEndpoint:</span><br>  <span class="hljs-attr">advertiseAddress:</span> <span class="hljs-number">10.31</span><span class="hljs-number">.188</span><span class="hljs-number">.1</span><br>  <span class="hljs-attr">bindPort:</span> <span class="hljs-number">6443</span><br><span class="hljs-attr">nodeRegistration:</span><br>  <span class="hljs-attr">criSocket:</span> <span class="hljs-string">/var/run/dockershim.sock</span><br>  <span class="hljs-attr">imagePullPolicy:</span> <span class="hljs-string">IfNotPresent</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">tiny-cilium-master-188-1.k8s.tcinternal</span><br>  <span class="hljs-attr">taints:</span> <span class="hljs-literal">null</span><br><span class="hljs-meta">---</span><br><span class="hljs-attr">apiServer:</span><br>  <span class="hljs-attr">timeoutForControlPlane:</span> <span class="hljs-string">4m0s</span><br><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">kubeadm.k8s.io/v1beta3</span><br><span class="hljs-attr">certificatesDir:</span> <span class="hljs-string">/etc/kubernetes/pki</span><br><span class="hljs-attr">clusterName:</span> <span class="hljs-string">kubernetes</span><br><span class="hljs-attr">controllerManager:</span> &#123;&#125;<br><span class="hljs-attr">dns:</span> &#123;&#125;<br><span class="hljs-attr">etcd:</span><br>  <span class="hljs-attr">local:</span><br>    <span class="hljs-attr">dataDir:</span> <span class="hljs-string">/var/lib/etcd</span><br><span class="hljs-attr">imageRepository:</span> <span class="hljs-string">registry.aliyuncs.com/google_containers</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">ClusterConfiguration</span><br><span class="hljs-attr">kubernetesVersion:</span> <span class="hljs-number">1.23</span><span class="hljs-number">.6</span><br><span class="hljs-attr">networking:</span><br>  <span class="hljs-attr">dnsDomain:</span> <span class="hljs-string">cili-cluster.tclocal</span><br>  <span class="hljs-attr">serviceSubnet:</span> <span class="hljs-number">10.188</span><span class="hljs-number">.0</span><span class="hljs-number">.0</span><span class="hljs-string">/18</span><br>  <span class="hljs-attr">podSubnet:</span> <span class="hljs-number">10.188</span><span class="hljs-number">.64</span><span class="hljs-number">.0</span><span class="hljs-string">/18</span><br><span class="hljs-attr">scheduler:</span> &#123;&#125;<br><span class="hljs-meta">---</span><br><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">kubeproxy.config.k8s.io/v1alpha1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">KubeProxyConfiguration</span><br><span class="hljs-attr">mode:</span> <span class="hljs-string">ipvs</span><br></code></pre></div></td></tr></table></figure>

<h2 id="4-2-初始化集群"><a href="#4-2-初始化集群" class="headerlink" title="4.2 初始化集群"></a>4.2 初始化集群</h2><p>此时我们再查看对应的配置文件中的镜像版本，就会发现已经变成了对应阿里云镜像源的版本</p>
<figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash"><span class="hljs-comment"># 查看一下对应的镜像版本，确定配置文件是否生效</span><br>$ kubeadm config images list --config kubeadm-cilium.conf<br>registry.aliyuncs.com/google_containers/kube-apiserver:v1.23.6<br>registry.aliyuncs.com/google_containers/kube-controller-manager:v1.23.6<br>registry.aliyuncs.com/google_containers/kube-scheduler:v1.23.6<br>registry.aliyuncs.com/google_containers/kube-proxy:v1.23.6<br>registry.aliyuncs.com/google_containers/pause:3.6<br>registry.aliyuncs.com/google_containers/etcd:3.5.1-0<br>registry.aliyuncs.com/google_containers/coredns:v1.8.6<br><br><span class="hljs-comment"># 确认没问题之后我们直接拉取镜像</span><br>$ kubeadm config images pull --config kubeadm-cilium.conf<br>[config/images] Pulled registry.aliyuncs.com/google_containers/kube-apiserver:v1.23.6<br>[config/images] Pulled registry.aliyuncs.com/google_containers/kube-controller-manager:v1.23.6<br>[config/images] Pulled registry.aliyuncs.com/google_containers/kube-scheduler:v1.23.6<br>[config/images] Pulled registry.aliyuncs.com/google_containers/kube-proxy:v1.23.6<br>[config/images] Pulled registry.aliyuncs.com/google_containers/pause:3.6<br>[config/images] Pulled registry.aliyuncs.com/google_containers/etcd:3.5.1-0<br>[config/images] Pulled registry.aliyuncs.com/google_containers/coredns:v1.8.6<br><br><span class="hljs-comment"># 初始化</span><br>$ kubeadm init --config kubeadm-cilium.conf<br>[init] Using Kubernetes version: v1.23.6<br>[preflight] Running pre-flight checks<br>[preflight] Pulling images required <span class="hljs-keyword">for</span> setting up a Kubernetes cluster<br>[preflight] This might take a minute or two, depending on the speed of your internet connection<br>[preflight] You can also perform this action <span class="hljs-keyword">in</span> beforehand using <span class="hljs-string">&#x27;kubeadm config images pull&#x27;</span><br>...此处略去一堆输出...<br></code></pre></div></td></tr></table></figure>
<p>当我们看到下面这个输出结果的时候，我们的集群就算是初始化成功了。</p>
<figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">Your Kubernetes control-plane has initialized successfully!<br><br>To start using your cluster, you need to run the following as a regular user:<br><br>  <span class="hljs-built_in">mkdir</span> -p <span class="hljs-variable">$HOME</span>/.kube<br>  sudo <span class="hljs-built_in">cp</span> -i /etc/kubernetes/admin.conf <span class="hljs-variable">$HOME</span>/.kube/config<br>  sudo <span class="hljs-built_in">chown</span> $(<span class="hljs-built_in">id</span> -u):$(<span class="hljs-built_in">id</span> -g) <span class="hljs-variable">$HOME</span>/.kube/config<br><br>Alternatively, <span class="hljs-keyword">if</span> you are the root user, you can run:<br><br>  <span class="hljs-built_in">export</span> KUBECONFIG=/etc/kubernetes/admin.conf<br><br>You should now deploy a pod network to the cluster.<br>Run <span class="hljs-string">&quot;kubectl apply -f [podnetwork].yaml&quot;</span> with one of the options listed at:<br>  https://kubernetes.io/docs/concepts/cluster-administration/addons/<br><br>Then you can <span class="hljs-built_in">join</span> any number of worker nodes by running the following on each as root:<br><br>kubeadm <span class="hljs-built_in">join</span> 10.31.188.1:6443 --token abcdef.0123456789abcdef \<br>        --discovery-token-ca-cert-hash sha256:fbe33f0dbda199b487a78948a4c693660d742d0dfc270bad2963a035b4971ade<br></code></pre></div></td></tr></table></figure>

<h2 id="4-3-配置kubeconfig"><a href="#4-3-配置kubeconfig" class="headerlink" title="4.3 配置kubeconfig"></a>4.3 配置kubeconfig</h2><p>刚初始化成功之后，我们还没办法马上查看k8s集群信息，需要配置kubeconfig相关参数才能正常使用kubectl连接apiserver读取集群信息。</p>
<figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash"><span class="hljs-comment"># 对于非root用户，可以这样操作</span><br><span class="hljs-built_in">mkdir</span> -p <span class="hljs-variable">$HOME</span>/.kube<br>sudo <span class="hljs-built_in">cp</span> -i /etc/kubernetes/admin.conf <span class="hljs-variable">$HOME</span>/.kube/config<br>sudo <span class="hljs-built_in">chown</span> $(<span class="hljs-built_in">id</span> -u):$(<span class="hljs-built_in">id</span> -g) <span class="hljs-variable">$HOME</span>/.kube/config<br><br><span class="hljs-comment"># 如果是root用户，可以直接导入环境变量</span><br><span class="hljs-built_in">export</span> KUBECONFIG=/etc/kubernetes/admin.conf<br><br><span class="hljs-comment"># 添加kubectl的自动补全功能</span><br><span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;source &lt;(kubectl completion bash)&quot;</span> &gt;&gt; ~/.bashrc<br></code></pre></div></td></tr></table></figure>

<blockquote>
<p>前面我们提到过<code>kubectl</code>不一定要安装在集群内，实际上只要是任何一台能连接到<code>apiserver</code>的机器上面都可以安装<code>kubectl</code>并且根据步骤配置<code>kubeconfig</code>，就可以使用<code>kubectl</code>命令行来管理对应的k8s集群。</p>
</blockquote>
<p>配置完成后，我们再执行相关命令就可以查看集群的信息了。</p>
<figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ kubectl cluster-info<br>Kubernetes control plane is running at https://10.31.188.1:6443<br>CoreDNS is running at https://10.31.188.1:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy<br><br>To further debug and diagnose cluster problems, use <span class="hljs-string">&#x27;kubectl cluster-info dump&#x27;</span>.<br><br><br>$ kubectl get nodes -o wide<br>NAME                                      STATUS     ROLES                  AGE   VERSION   INTERNAL-IP   EXTERNAL-IP   OS-IMAGE                KERNEL-VERSION               CONTAINER-RUNTIME<br>tiny-cilium-master-188-1.k8s.tcinternal   NotReady   control-plane,master   84s   v1.23.6   10.31.188.1   &lt;none&gt;        CentOS Linux 7 (Core)   5.17.6-1.el7.elrepo.x86_64   docker://20.10.14<br><br>$ kubectl get pods -A -o wide<br>NAMESPACE     NAME                                                              READY   STATUS    RESTARTS   AGE   IP            NODE                                      NOMINATED NODE   READINESS GATES<br>kube-system   coredns-6d8c4cb4d-285cl                                           0/1     Pending   0          78s   &lt;none&gt;        &lt;none&gt;                                    &lt;none&gt;           &lt;none&gt;<br>kube-system   coredns-6d8c4cb4d-6zntv                                           0/1     Pending   0          78s   &lt;none&gt;        &lt;none&gt;                                    &lt;none&gt;           &lt;none&gt;<br>kube-system   etcd-tiny-cilium-master-188-1.k8s.tcinternal                      1/1     Running   0          90s   10.31.188.1   tiny-cilium-master-188-1.k8s.tcinternal   &lt;none&gt;           &lt;none&gt;<br>kube-system   kube-apiserver-tiny-cilium-master-188-1.k8s.tcinternal            1/1     Running   0          92s   10.31.188.1   tiny-cilium-master-188-1.k8s.tcinternal   &lt;none&gt;           &lt;none&gt;<br>kube-system   kube-controller-manager-tiny-cilium-master-188-1.k8s.tcinternal   1/1     Running   0          90s   10.31.188.1   tiny-cilium-master-188-1.k8s.tcinternal   &lt;none&gt;           &lt;none&gt;<br>kube-system   kube-proxy-m7q5n                                                  1/1     Running   0          78s   10.31.188.1   tiny-cilium-master-188-1.k8s.tcinternal   &lt;none&gt;           &lt;none&gt;<br>kube-system   kube-scheduler-tiny-cilium-master-188-1.k8s.tcinternal            1/1     Running   0          91s   10.31.188.1   tiny-cilium-master-188-1.k8s.tcinternal   &lt;none&gt;           &lt;none&gt;<br></code></pre></div></td></tr></table></figure>

<h2 id="4-4-添加worker节点"><a href="#4-4-添加worker节点" class="headerlink" title="4.4 添加worker节点"></a>4.4 添加worker节点</h2><p>这时候我们还需要继续添加剩下的两个节点作为worker节点运行负载，直接在剩下的节点上面运行集群初始化成功时输出的命令就可以成功加入集群。</p>
<figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ kubeadm <span class="hljs-built_in">join</span> 10.31.188.1:6443 --token abcdef.0123456789abcdef \<br>&gt;         --discovery-token-ca-cert-hash sha256:fbe33f0dbda199b487a78948a4c693660d742d0dfc270bad2963a035b4971ade<br>[preflight] Running pre-flight checks<br>[preflight] Reading configuration from the cluster...<br>[preflight] FYI: You can look at this config file with <span class="hljs-string">&#x27;kubectl -n kube-system get cm kubeadm-config -o yaml&#x27;</span><br>[kubelet-start] Writing kubelet configuration to file <span class="hljs-string">&quot;/var/lib/kubelet/config.yaml&quot;</span><br>[kubelet-start] Writing kubelet environment file with flags to file <span class="hljs-string">&quot;/var/lib/kubelet/kubeadm-flags.env&quot;</span><br>[kubelet-start] Starting the kubelet<br>[kubelet-start] Waiting <span class="hljs-keyword">for</span> the kubelet to perform the TLS Bootstrap...<br><br>This node has joined the cluster:<br>* Certificate signing request was sent to apiserver and a response was received.<br>* The Kubelet was informed of the new secure connection details.<br><br>Run <span class="hljs-string">&#x27;kubectl get nodes&#x27;</span> on the control-plane to see this node <span class="hljs-built_in">join</span> the cluster.<br></code></pre></div></td></tr></table></figure>

<p>如果不小心没保存初始化成功的输出信息也没有关系，我们可以使用kubectl工具查看或者生成token</p>
<figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash"><span class="hljs-comment"># 查看现有的token列表</span><br>$ kubeadm token list<br>TOKEN                     TTL         EXPIRES                USAGES                   DESCRIPTION                                                EXTRA GROUPS<br>abcdef.0123456789abcdef   23h         2022-05-10T05:46:11Z   authentication,signing   &lt;none&gt;                                                     system:bootstrappers:kubeadm:default-node-token<br><br><span class="hljs-comment"># 如果token已经失效，那就再创建一个新的token</span><br>$ kubeadm token create<br>xd468t.co8ye3su70bojo2k<br>$ kubeadm token list<br>TOKEN                     TTL         EXPIRES                USAGES                   DESCRIPTION                                                EXTRA GROUPS<br>abcdef.0123456789abcdef   23h         2022-05-10T05:46:11Z   authentication,signing   &lt;none&gt;                                                     system:bootstrappers:kubeadm:default-node-token<br>xd468t.co8ye3su70bojo2k   23h         2022-05-10T05:58:40Z   authentication,signing   &lt;none&gt;                                                     system:bootstrappers:kubeadm:default-node-token<br><br><span class="hljs-comment"># 如果找不到--discovery-token-ca-cert-hash参数，则可以在master节点上使用openssl工具来获取</span><br>$ openssl x509 -pubkey -<span class="hljs-keyword">in</span> /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2&gt;/dev/null | openssl dgst -sha256 -hex | sed <span class="hljs-string">&#x27;s/^.* //&#x27;</span><br>0d68339d3e5a045dc093470321f8f6334223e97f360542477c4f480bda34d72a<br></code></pre></div></td></tr></table></figure>



<p>添加完成之后我们再查看集群的节点可以发现这时候已经多了两个node，但是此时节点的状态还是<code>NotReady</code>，接下来就需要部署CNI了。</p>
<figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ kubectl get nodes<br>NAME                                       STATUS     ROLES                  AGE     VERSION<br>tiny-cilium-master-188-1.k8s.tcinternal    NotReady   control-plane,master   2m47s   v1.23.6<br>tiny-cilium-worker-188-11.k8s.tcinternal   NotReady   &lt;none&gt;                 41s     v1.23.6<br>tiny-cilium-worker-188-12.k8s.tcinternal   NotReady   &lt;none&gt;                 30s     v1.23.6<br></code></pre></div></td></tr></table></figure>

<h1 id="5、安装CNI"><a href="#5、安装CNI" class="headerlink" title="5、安装CNI"></a>5、安装CNI</h1><h2 id="5-1-安装cilium"><a href="#5-1-安装cilium" class="headerlink" title="5.1 安装cilium"></a>5.1 安装cilium</h2><p>快速安装的教程可以参考<a target="_blank" rel="noopener" href="https://docs.cilium.io/en/latest/gettingstarted/k8s-install-default/">官网文档</a>，基本的安装思路就是先下载cilium官方的cli工具，然后使用cli工具进行安装。</p>
<p>这种安装方式的优势就是简单快捷，缺点就是缺少自定义参数配置的功能，只能使用官方原先设置的默认参数，比较适合快速初始化搭建可用环境用来学习和测试。</p>
<figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash"><span class="hljs-comment"># cilium的cli工具是一个二进制的可执行文件</span><br>$ curl -L --remote-name-all https://github.com/cilium/cilium-cli/releases/latest/download/cilium-linux-amd64.tar.gz&#123;,.<span class="hljs-built_in">sha256sum</span>&#125;<br>$ <span class="hljs-built_in">sha256sum</span> --check cilium-linux-amd64.tar.gz.sha256sum<br>cilium-linux-amd64.tar.gz: OK<br>$ sudo tar xzvfC cilium-linux-amd64.tar.gz /usr/local/bin<br>cilium<br><br><span class="hljs-comment"># 使用该命令即可完成cilium的安装</span><br>$ cilium install<br>ℹ️  using Cilium version <span class="hljs-string">&quot;v1.11.3&quot;</span><br>🔮 Auto-detected cluster name: kubernetes<br>🔮 Auto-detected IPAM mode: cluster-pool<br>ℹ️  helm template --namespace kube-system cilium cilium/cilium --version 1.11.3 --<span class="hljs-built_in">set</span> cluster.id=0,cluster.name=kubernetes,encryption.nodeEncryption=<span class="hljs-literal">false</span>,ipam.mode=cluster-pool,kubeProxyReplacement=disabled,operator.replicas=1,serviceAccounts.cilium.name=cilium,serviceAccounts.operator.name=cilium-operator<br>ℹ️  Storing helm values file <span class="hljs-keyword">in</span> kube-system/cilium-cli-helm-values Secret<br>🔑 Created CA <span class="hljs-keyword">in</span> secret cilium-ca<br>🔑 Generating certificates <span class="hljs-keyword">for</span> Hubble...<br>🚀 Creating Service accounts...<br>🚀 Creating Cluster roles...<br>🚀 Creating ConfigMap <span class="hljs-keyword">for</span> Cilium version 1.11.3...<br>🚀 Creating Agent DaemonSet...<br>level=warning msg=<span class="hljs-string">&quot;spec.template.spec.affinity.nodeAffinity.requiredDuringSchedulingIgnoredDuringExecution.nodeSelectorTerms[1].matchExpressions[0].key: beta.kubernetes.io/os is deprecated since v1.14; use \&quot;kubernetes.io/os\&quot; instead&quot;</span> subsys=klog<br>level=warning msg=<span class="hljs-string">&quot;spec.template.metadata.annotations[scheduler.alpha.kubernetes.io/critical-pod]: non-functional in v1.16+; use the \&quot;priorityClassName\&quot; field instead&quot;</span> subsys=klog<br>🚀 Creating Operator Deployment...<br>⌛ Waiting <span class="hljs-keyword">for</span> Cilium to be installed and ready...<br>✅ Cilium was successfully installed! Run <span class="hljs-string">&#x27;cilium status&#x27;</span> to view installation health<br><br><span class="hljs-comment"># 查看cilium的状态</span><br>$ cilium status<br>    /¯¯\<br> /¯¯\__/¯¯\    Cilium:         OK<br> \__/¯¯\__/    Operator:       OK<br> /¯¯\__/¯¯\    Hubble:         disabled<br> \__/¯¯\__/    ClusterMesh:    disabled<br>    \__/<br><br>DaemonSet         cilium             Desired: 3, Ready: 3/3, Available: 3/3<br>Deployment        cilium-operator    Desired: 1, Ready: 1/1, Available: 1/1<br>Containers:       cilium-operator    Running: 1<br>                  cilium             Running: 3<br>Cluster Pods:     2/2 managed by Cilium<br>Image versions    cilium             quay.io/cilium/cilium:v1.11.3@sha256:cb6aac121e348abd61a692c435a90a6e2ad3f25baa9915346be7b333de8a767f: 3<br>                  cilium-operator    quay.io/cilium/operator-generic:v1.11.3@sha256:5b81db7a32cb7e2d00bb3cf332277ec2b3be239d9e94a8d979915f4e6648c787: 1<br></code></pre></div></td></tr></table></figure>



<h2 id="5-2-配置hubble"><a href="#5-2-配置hubble" class="headerlink" title="5.2 配置hubble"></a>5.2 配置hubble</h2><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash"><span class="hljs-comment"># 我们先使用cilium-cli工具在k8s集群中部署hubble，只需要下面一条命令即可</span><br>$ cilium hubble <span class="hljs-built_in">enable</span><br>🔑 Found CA <span class="hljs-keyword">in</span> secret cilium-ca<br>ℹ️  helm template --namespace kube-system cilium cilium/cilium --version 1.11.3 --<span class="hljs-built_in">set</span> cluster.id=0,cluster.name=kubernetes,encryption.nodeEncryption=<span class="hljs-literal">false</span>,hubble.enabled=<span class="hljs-literal">true</span>,hubble.relay.enabled=<span class="hljs-literal">true</span>,hubble.tls.ca.cert=LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUNGRENDQWJxZ0F3SUJBZ0lVSDRQcit1UU0xSXZtdWQvVlV3YWlycGllSEZBd0NnWUlLb1pJemowRUF3SXcKYURFTE1Ba0dBMVVFQmhNQ1ZWTXhGakFVQmdOVkJBZ1REVk5oYmlCR2NtRnVZMmx6WTI4eEN6QUpCZ05WQkFjVApBa05CTVE4d0RRWURWUVFLRXdaRGFXeHBkVzB4RHpBTkJnTlZCQXNUQmtOcGJHbDFiVEVTTUJBR0ExVUVBeE1KClEybHNhWFZ0SUVOQk1CNFhEVEl5TURVd09UQTVNREF3TUZvWERUSTNNRFV3T0RBNU1EQXdNRm93YURFTE1Ba0cKQTFVRUJoTUNWVk14RmpBVUJnTlZCQWdURFZOaGJpQkdjbUZ1WTJselkyOHhDekFKQmdOVkJBY1RBa05CTVE4dwpEUVlEVlFRS0V3WkRhV3hwZFcweER6QU5CZ05WQkFzVEJrTnBiR2wxYlRFU01CQUdBMVVFQXhNSlEybHNhWFZ0CklFTkJNRmt3RXdZSEtvWkl6ajBDQVFZSUtvWkl6ajBEQVFjRFFnQUU3Z21EQ05WOERseEIxS3VYYzhEdndCeUoKWUxuSENZNjVDWUhBb3ZBY3FUM3drcitLVVNwelcyVjN0QW9IaFdZV0UyQ2lUNjNIOXZLV1ZRY3pHeXp1T0tOQwpNRUF3RGdZRFZSMFBBUUgvQkFRREFnRUdNQThHQTFVZEV3RUIvd1FGTUFNQkFmOHdIUVlEVlIwT0JCWUVGQmMrClNDb3F1Y0JBc09sdDBWaEVCbkwyYjEyNE1Bb0dDQ3FHU000OUJBTUNBMGdBTUVVQ0lRRDJsNWVqaDVLVTkySysKSHJJUXIweUwrL05pZ3NSUHRBblA5T3lDcHExbFJBSWdYeGY5a2t5N2xYU0pOYmpkREFjbnBrNlJFTFp2eEkzbQpKaG9JRkRlbER0dz0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=,hubble.tls.ca.key=[--- REDACTED WHEN PRINTING TO TERMINAL (USE --redact-helm-certificate-keys=<span class="hljs-literal">false</span> TO PRINT) ---],ipam.mode=cluster-pool,kubeProxyReplacement=disabled,operator.replicas=1,serviceAccounts.cilium.name=cilium,serviceAccounts.operator.name=cilium-operator<br>✨ Patching ConfigMap cilium-config to <span class="hljs-built_in">enable</span> Hubble...<br>🚀 Creating ConfigMap <span class="hljs-keyword">for</span> Cilium version 1.11.3...<br>♻️  Restarted Cilium pods<br>⌛ Waiting <span class="hljs-keyword">for</span> Cilium to become ready before deploying other Hubble component(s)...<br>✨ Generating certificates...<br>🔑 Generating certificates <span class="hljs-keyword">for</span> Relay...<br>✨ Deploying Relay...<br>⌛ Waiting <span class="hljs-keyword">for</span> Hubble to be installed...<br>ℹ️  Storing helm values file <span class="hljs-keyword">in</span> kube-system/cilium-cli-helm-values Secret<br>✅ Hubble was successfully enabled!<br><br><br><span class="hljs-comment"># 安装hubble-cli工具，安装逻辑和cilium-cli的逻辑相似</span><br>$ <span class="hljs-built_in">export</span> HUBBLE_VERSION=$(curl -s https://raw.githubusercontent.com/cilium/hubble/master/stable.txt)<br>$ curl -L --remote-name-all https://github.com/cilium/hubble/releases/download/<span class="hljs-variable">$HUBBLE_VERSION</span>/hubble-linux-amd64.tar.gz&#123;,.<span class="hljs-built_in">sha256sum</span>&#125;<br>$ <span class="hljs-built_in">sha256sum</span> --check hubble-linux-amd64.tar.gz.sha256sum<br>hubble-linux-amd64.tar.gz: OK<br>$ sudo tar xzvfC hubble-linux-amd64.tar.gz /usr/local/bin<br>hubble<br><br><span class="hljs-comment"># 首先我们要开启hubble的api，使用cilium-cli开启转发</span><br>$ cilium hubble port-forward&amp;<br>[1] 15512<br>$ kubectl get svc -n kube-system<br>NAME           TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                  AGE<br>hubble-relay   ClusterIP   10.188.55.197   &lt;none&gt;        80/TCP                   16h<br>hubble-ui      ClusterIP   10.188.17.78    &lt;none&gt;        80/TCP                   16h<br>kube-dns       ClusterIP   10.188.0.10     &lt;none&gt;        53/UDP,53/TCP,9153/TCP   17h<br>$ netstat -ntulp | grep 4245<br>tcp        0      0 0.0.0.0:4245            0.0.0.0:*               LISTEN      15527/kubectl<br>tcp6       0      0 :::4245                 :::*                    LISTEN      15527/kubectl<br><br><span class="hljs-comment"># 实际上执行的操作等同于下面这个命令</span><br><span class="hljs-comment"># kubectl port-forward -n kube-system svc/hubble-relay --address 0.0.0.0 --address :: 4245:80</span><br><br><br><span class="hljs-comment"># 测试和hubble-api的连通性</span><br>$ hubble status<br>Healthcheck (via localhost:4245): Ok<br>Current/Max Flows: 12,285/12,285 (100.00%)<br>Flows/s: 28.58<br>Connected Nodes: 3/3<br><br><span class="hljs-comment"># 使用hubble命令查看数据的转发情况</span><br>$ hubble observe<br>Handling connection <span class="hljs-keyword">for</span> 4245<br>May  9 09:33:25.861: 10.0.1.47:44484 -&gt; cilium-test/echo-same-node-5767b7b99d-xhzpb:8080 to-endpoint FORWARDED (TCP Flags: ACK, PSH)<br>May  9 09:33:25.863: 10.0.1.47:44484 &lt;- cilium-test/echo-same-node-5767b7b99d-xhzpb:8080 to-stack FORWARDED (TCP Flags: ACK, PSH)<br>May  9 09:33:25.864: 10.0.1.47:44484 -&gt; cilium-test/echo-same-node-5767b7b99d-xhzpb:8080 to-endpoint FORWARDED (TCP Flags: ACK, FIN)<br>...此处略去一堆输出...<br><br><span class="hljs-comment"># 开启hubble ui组件</span><br>$ cilium hubble <span class="hljs-built_in">enable</span> --ui<br>🔑 Found CA <span class="hljs-keyword">in</span> secret cilium-ca<br>ℹ️  helm template --namespace kube-system cilium cilium/cilium --version 1.11.3 --<span class="hljs-built_in">set</span> cluster.id=0,cluster.name=kubernetes,encryption.nodeEncryption=<span class="hljs-literal">false</span>,hubble.enabled=<span class="hljs-literal">true</span>,hubble.relay.enabled=<span class="hljs-literal">true</span>,hubble.tls.ca.cert=LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUNGRENDQWJxZ0F3SUJBZ0lVSDRQcit1UU0xSXZtdWQvVlV3YWlycGllSEZBd0NnWUlLb1pJemowRUF3SXcKYURFTE1Ba0dBMVVFQmhNQ1ZWTXhGakFVQmdOVkJBZ1REVk5oYmlCR2NtRnVZMmx6WTI4eEN6QUpCZ05WQkFjVApBa05CTVE4d0RRWURWUVFLRXdaRGFXeHBkVzB4RHpBTkJnTlZCQXNUQmtOcGJHbDFiVEVTTUJBR0ExVUVBeE1KClEybHNhWFZ0SUVOQk1CNFhEVEl5TURVd09UQTVNREF3TUZvWERUSTNNRFV3T0RBNU1EQXdNRm93YURFTE1Ba0cKQTFVRUJoTUNWVk14RmpBVUJnTlZCQWdURFZOaGJpQkdjbUZ1WTJselkyOHhDekFKQmdOVkJBY1RBa05CTVE4dwpEUVlEVlFRS0V3WkRhV3hwZFcweER6QU5CZ05WQkFzVEJrTnBiR2wxYlRFU01CQUdBMVVFQXhNSlEybHNhWFZ0CklFTkJNRmt3RXdZSEtvWkl6ajBDQVFZSUtvWkl6ajBEQVFjRFFnQUU3Z21EQ05WOERseEIxS3VYYzhEdndCeUoKWUxuSENZNjVDWUhBb3ZBY3FUM3drcitLVVNwelcyVjN0QW9IaFdZV0UyQ2lUNjNIOXZLV1ZRY3pHeXp1T0tOQwpNRUF3RGdZRFZSMFBBUUgvQkFRREFnRUdNQThHQTFVZEV3RUIvd1FGTUFNQkFmOHdIUVlEVlIwT0JCWUVGQmMrClNDb3F1Y0JBc09sdDBWaEVCbkwyYjEyNE1Bb0dDQ3FHU000OUJBTUNBMGdBTUVVQ0lRRDJsNWVqaDVLVTkySysKSHJJUXIweUwrL05pZ3NSUHRBblA5T3lDcHExbFJBSWdYeGY5a2t5N2xYU0pOYmpkREFjbnBrNlJFTFp2eEkzbQpKaG9JRkRlbER0dz0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=,hubble.tls.ca.key=[--- REDACTED WHEN PRINTING TO TERMINAL (USE --redact-helm-certificate-keys=<span class="hljs-literal">false</span> TO PRINT) ---],hubble.ui.enabled=<span class="hljs-literal">true</span>,hubble.ui.securityContext.enabled=<span class="hljs-literal">false</span>,ipam.mode=cluster-pool,kubeProxyReplacement=disabled,operator.replicas=1,serviceAccounts.cilium.name=cilium,serviceAccounts.operator.name=cilium-operator<br>✨ Patching ConfigMap cilium-config to <span class="hljs-built_in">enable</span> Hubble...<br>🚀 Creating ConfigMap <span class="hljs-keyword">for</span> Cilium version 1.11.3...<br>♻️  Restarted Cilium pods<br>⌛ Waiting <span class="hljs-keyword">for</span> Cilium to become ready before deploying other Hubble component(s)...<br>✅ Relay is already deployed<br>✨ Deploying Hubble UI and Hubble UI Backend...<br>⌛ Waiting <span class="hljs-keyword">for</span> Hubble to be installed...<br>ℹ️  Storing helm values file <span class="hljs-keyword">in</span> kube-system/cilium-cli-helm-values Secret<br>✅ Hubble was successfully enabled!<br><br><span class="hljs-comment"># 实际上这时候我们再查看k8s集群的状态可以看到部署了一个名为hubble-ui的deployment</span><br>$ kubectl get deployment -n kube-system | grep hubble<br>hubble-relay      1/1     1            1           17h<br>hubble-ui         1/1     1            1           17h<br>$ kubectl get svc -n kube-system | grep hubble<br>hubble-relay   ClusterIP   10.188.55.197   &lt;none&gt;        80/TCP                   17h<br>hubble-ui      ClusterIP   10.188.17.78    &lt;none&gt;        80/TCP                   17h<br><br><span class="hljs-comment"># 将hubble-ui这个服务的80端口暴露到宿主机上面的12000端口上面</span><br>$ cilium hubble ui&amp;<br>[2] 5809<br>ℹ️  Opening <span class="hljs-string">&quot;http://localhost:12000&quot;</span> <span class="hljs-keyword">in</span> your browser...<br><span class="hljs-comment"># 实际上执行的操作等同于下面这个命令</span><br><span class="hljs-comment"># kubectl port-forward -n kube-system svc/hubble-ui --address 0.0.0.0 --address :: 12000:80</span><br></code></pre></div></td></tr></table></figure>

<p>访问k8s宿主机节点的IP+端口就可以看到hubble-ui的界面了</p>
<p><img src="https://resource.tinychen.com/202205091755694.png" srcset="/img/loading.gif" lazyload></p>
<p>最后所有的相关服务都部署完成之后，我们再检查一下整个cilium的状态</p>
<figure class="highlight swift"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs swift">$ cilium status<br>    <span class="hljs-operator">/</span>¯¯\<br> <span class="hljs-regexp">/¯¯\__/</span>¯¯\    <span class="hljs-type">Cilium</span>:         <span class="hljs-type">OK</span><br> \__<span class="hljs-regexp">/¯¯\__/</span>    <span class="hljs-type">Operator</span>:       <span class="hljs-type">OK</span><br> <span class="hljs-regexp">/¯¯\__/</span>¯¯\    <span class="hljs-type">Hubble</span>:         <span class="hljs-type">OK</span><br> \__<span class="hljs-regexp">/¯¯\__/</span>    <span class="hljs-type">ClusterMesh</span>:    disabled<br>    \__<span class="hljs-operator">/</span><br><br><span class="hljs-type">Deployment</span>        cilium<span class="hljs-operator">-</span><span class="hljs-keyword">operator</span>    <span class="hljs-type">Desired</span>: <span class="hljs-number">1</span>, <span class="hljs-type">Ready</span>: <span class="hljs-number">1</span><span class="hljs-regexp">/1, Available: 1/</span><span class="hljs-number">1</span><br><span class="hljs-type">Deployment</span>        hubble<span class="hljs-operator">-</span>relay       <span class="hljs-type">Desired</span>: <span class="hljs-number">1</span>, <span class="hljs-type">Ready</span>: <span class="hljs-number">1</span><span class="hljs-regexp">/1, Available: 1/</span><span class="hljs-number">1</span><br><span class="hljs-type">Deployment</span>        hubble<span class="hljs-operator">-</span>ui          <span class="hljs-type">Desired</span>: <span class="hljs-number">1</span>, <span class="hljs-type">Ready</span>: <span class="hljs-number">1</span><span class="hljs-regexp">/1, Available: 1/</span><span class="hljs-number">1</span><br><span class="hljs-type">DaemonSet</span>         cilium             <span class="hljs-type">Desired</span>: <span class="hljs-number">3</span>, <span class="hljs-type">Ready</span>: <span class="hljs-number">3</span><span class="hljs-regexp">/3, Available: 3/</span><span class="hljs-number">3</span><br><span class="hljs-type">Containers</span>:       cilium             <span class="hljs-type">Running</span>: <span class="hljs-number">3</span><br>                  cilium<span class="hljs-operator">-</span><span class="hljs-keyword">operator</span>    <span class="hljs-type">Running</span>: <span class="hljs-number">1</span><br>                  hubble<span class="hljs-operator">-</span>relay       <span class="hljs-type">Running</span>: <span class="hljs-number">1</span><br>                  hubble<span class="hljs-operator">-</span>ui          <span class="hljs-type">Running</span>: <span class="hljs-number">1</span><br><span class="hljs-type">Cluster</span> <span class="hljs-type">Pods</span>:     <span class="hljs-number">8</span><span class="hljs-operator">/</span><span class="hljs-number">8</span> managed by <span class="hljs-type">Cilium</span><br><span class="hljs-type">Image</span> versions    cilium             quay.io<span class="hljs-regexp">/cilium/</span>cilium:v1.<span class="hljs-number">11.3</span><span class="hljs-meta">@sha256</span>:cb6aac121e348abd61a692c435a90a6e2ad3f25baa9915346be7b333de8a767f: <span class="hljs-number">3</span><br>                  cilium<span class="hljs-operator">-</span><span class="hljs-keyword">operator</span>    quay.io<span class="hljs-regexp">/cilium/</span><span class="hljs-keyword">operator</span><span class="hljs-operator">-</span>generic:v1.<span class="hljs-number">11.3</span><span class="hljs-meta">@sha256</span>:5b81db7a32cb7e2d00bb3cf332277ec2b3be239d9e94a8d979915f4e6648c787: <span class="hljs-number">1</span><br>                  hubble<span class="hljs-operator">-</span>relay       quay.io<span class="hljs-regexp">/cilium/</span>hubble<span class="hljs-operator">-</span>relay:v1.<span class="hljs-number">11.3</span><span class="hljs-meta">@sha256</span>:7256ec111259a79b4f0e0f80ba4256ea23bd472e1fc3f0865975c2ed113ccb97: <span class="hljs-number">1</span><br>                  hubble<span class="hljs-operator">-</span>ui          quay.io<span class="hljs-regexp">/cilium/</span>hubble<span class="hljs-operator">-</span>ui:v0.<span class="hljs-number">8.5</span><span class="hljs-meta">@sha256</span>:4eaca1ec1741043cfba6066a165b3bf251590cf4ac66371c4f63fbed2224ebb4: <span class="hljs-number">1</span><br>                  hubble<span class="hljs-operator">-</span>ui          quay.io<span class="hljs-regexp">/cilium/</span>hubble<span class="hljs-operator">-</span>ui<span class="hljs-operator">-</span>backend:v0.<span class="hljs-number">8.5</span><span class="hljs-meta">@sha256</span>:2bce50cf6c32719d072706f7ceccad654bfa907b2745a496da99610776fe31ed: <span class="hljs-number">1</span><br>                  hubble<span class="hljs-operator">-</span>ui          docker.io<span class="hljs-regexp">/envoyproxy/</span>envoy:v1.<span class="hljs-number">18.4</span><span class="hljs-meta">@sha256</span>:e5c2bb2870d0e59ce917a5100311813b4ede96ce4eb0c6bfa879e3fbe3e83935: <span class="hljs-number">1</span><br></code></pre></div></td></tr></table></figure>



<h1 id="6、部署测试用例"><a href="#6、部署测试用例" class="headerlink" title="6、部署测试用例"></a>6、部署测试用例</h1><p>集群部署完成之后我们在k8s集群中部署一个nginx测试一下是否能够正常工作。首先我们创建一个名为<code>nginx-quic</code>的命名空间（<code>namespace</code>），然后在这个命名空间内创建一个名为<code>nginx-quic-deployment</code>的<code>deployment</code>用来部署pod，最后再创建一个<code>service</code>用来暴露服务，这里我们先使用<code>nodeport</code>的方式暴露端口方便测试。</p>
<figure class="highlight yaml"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs yaml"><span class="hljs-string">$</span> <span class="hljs-string">cat</span> <span class="hljs-string">nginx-quic.yaml</span><br><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">Namespace</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">nginx-quic</span><br><br><span class="hljs-meta">---</span><br><span class="hljs-meta"></span><br><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">apps/v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">Deployment</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">nginx-quic-deployment</span><br>  <span class="hljs-attr">namespace:</span> <span class="hljs-string">nginx-quic</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">selector:</span><br>    <span class="hljs-attr">matchLabels:</span><br>      <span class="hljs-attr">app:</span> <span class="hljs-string">nginx-quic</span><br>  <span class="hljs-attr">replicas:</span> <span class="hljs-number">4</span><br>  <span class="hljs-attr">template:</span><br>    <span class="hljs-attr">metadata:</span><br>      <span class="hljs-attr">labels:</span><br>        <span class="hljs-attr">app:</span> <span class="hljs-string">nginx-quic</span><br>    <span class="hljs-attr">spec:</span><br>      <span class="hljs-attr">containers:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">nginx-quic</span><br>        <span class="hljs-attr">image:</span> <span class="hljs-string">tinychen777/nginx-quic:latest</span><br>        <span class="hljs-attr">imagePullPolicy:</span> <span class="hljs-string">IfNotPresent</span><br>        <span class="hljs-attr">ports:</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-attr">containerPort:</span> <span class="hljs-number">80</span><br><br><span class="hljs-meta">---</span><br><span class="hljs-meta"></span><br><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">Service</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">nginx-quic-service</span><br>  <span class="hljs-attr">namespace:</span> <span class="hljs-string">nginx-quic</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">externalTrafficPolicy:</span> <span class="hljs-string">Cluster</span><br>  <span class="hljs-attr">selector:</span><br>    <span class="hljs-attr">app:</span> <span class="hljs-string">nginx-quic</span><br>  <span class="hljs-attr">ports:</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-attr">protocol:</span> <span class="hljs-string">TCP</span><br>    <span class="hljs-attr">port:</span> <span class="hljs-number">8080</span> <span class="hljs-comment"># match for service access port</span><br>    <span class="hljs-attr">targetPort:</span> <span class="hljs-number">80</span> <span class="hljs-comment"># match for pod access port</span><br>    <span class="hljs-attr">nodePort:</span> <span class="hljs-number">30088</span> <span class="hljs-comment"># match for external access port</span><br>  <span class="hljs-attr">type:</span> <span class="hljs-string">NodePort</span><br></code></pre></div></td></tr></table></figure>

<p>部署完成后我们直接查看状态</p>
<figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash"><span class="hljs-comment"># 直接部署</span><br>$ kubectl apply -f nginx-quic.yaml<br>namespace/nginx-quic created<br>deployment.apps/nginx-quic-deployment created<br>service/nginx-quic-service created<br><br><span class="hljs-comment"># 查看deployment的运行状态</span><br>$ kubectl get deployment -o wide -n nginx-quic<br>NAME                    READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS   IMAGES                          SELECTOR<br>nginx-quic-deployment   4/4     4            4           17h   nginx-quic   tinychen777/nginx-quic:latest   app=nginx-quic<br><br><span class="hljs-comment"># 查看service的运行状态</span><br>$ kubectl get service -o wide -n nginx-quic<br>NAME                 TYPE       CLUSTER-IP     EXTERNAL-IP   PORT(S)          AGE   SELECTOR<br>nginx-quic-service   NodePort   10.188.0.200   &lt;none&gt;        8080:30088/TCP   17h   app=nginx-quic<br><br><span class="hljs-comment"># 查看pod的运行状态</span><br>$ kubectl get pods -o wide -n nginx-quic<br>NAME                                     READY   STATUS    RESTARTS      AGE   IP           NODE                                       NOMINATED NODE   READINESS GATES<br>nginx-quic-deployment-696d959797-26dzh   1/1     Running   1 (17h ago)   17h   10.0.2.58    tiny-cilium-worker-188-12.k8s.tcinternal   &lt;none&gt;           &lt;none&gt;<br>nginx-quic-deployment-696d959797-kw6bn   1/1     Running   1 (17h ago)   17h   10.0.2.207   tiny-cilium-worker-188-12.k8s.tcinternal   &lt;none&gt;           &lt;none&gt;<br>nginx-quic-deployment-696d959797-mdw99   1/1     Running   1 (17h ago)   17h   10.0.1.247   tiny-cilium-worker-188-11.k8s.tcinternal   &lt;none&gt;           &lt;none&gt;<br>nginx-quic-deployment-696d959797-x42zn   1/1     Running   1 (17h ago)   17h   10.0.1.60    tiny-cilium-worker-188-11.k8s.tcinternal   &lt;none&gt;           &lt;none&gt;<br><br><span class="hljs-comment"># 查看IPVS规则</span><br>$ ipvsadm -<span class="hljs-built_in">ln</span><br>IP Virtual Server version 1.2.1 (size=4096)<br>Prot LocalAddress:Port Scheduler Flags<br>  -&gt; RemoteAddress:Port           Forward Weight ActiveConn InActConn<br>TCP  172.17.0.1:30088 rr<br>  -&gt; 10.0.1.60:80                 Masq    1      0          0<br>  -&gt; 10.0.1.247:80                Masq    1      0          0<br>  -&gt; 10.0.2.58:80                 Masq    1      0          0<br>  -&gt; 10.0.2.207:80                Masq    1      0          0<br>TCP  10.0.0.226:30088 rr<br>  -&gt; 10.0.1.60:80                 Masq    1      0          0<br>  -&gt; 10.0.1.247:80                Masq    1      0          0<br>  -&gt; 10.0.2.58:80                 Masq    1      0          0<br>  -&gt; 10.0.2.207:80                Masq    1      0          0<br>TCP  10.31.188.1:30088 rr<br>  -&gt; 10.0.1.60:80                 Masq    1      0          0<br>  -&gt; 10.0.1.247:80                Masq    1      0          0<br>  -&gt; 10.0.2.58:80                 Masq    1      0          0<br>  -&gt; 10.0.2.207:80                Masq    1      0          0<br>TCP  10.188.0.200:8080 rr<br>  -&gt; 10.0.1.60:80                 Masq    1      0          0<br>  -&gt; 10.0.1.247:80                Masq    1      0          0<br>  -&gt; 10.0.2.58:80                 Masq    1      0          0<br>  -&gt; 10.0.2.207:80                Masq    1      0          0<br></code></pre></div></td></tr></table></figure>

<p>最后我们进行测试，这个nginx-quic的镜像默认情况下会返回在nginx容器中获得的用户请求的IP和端口</p>
<figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash"><span class="hljs-comment"># 首先我们在集群内进行测试</span><br><span class="hljs-comment"># 直接访问pod</span><br>$ curl 10.0.2.58:80<br>10.0.0.226:52312<br><span class="hljs-comment"># 直接访问service的ClusterIP，这时请求会被转发到pod中</span><br>$ curl 10.188.0.200:8080<br>10.0.0.226:36228<br><span class="hljs-comment"># 直接访问nodeport，这时请求会被转发到pod中，不会经过ClusterIP</span><br><span class="hljs-comment"># 此时实际返回的IP要取决于被转发到的后端pod是否在当前的k8s节点上</span><br>$ curl 10.31.188.1:30088<br>10.0.0.226:38034<br>$ curl 10.31.188.11:30088<br>10.31.188.11:24371<br>$ curl 10.31.188.12:30088<br>10.31.188.12:56919<br>$ curl 10.31.188.12:30088<br>10.0.2.151:49222<br><br><span class="hljs-comment"># 接着我们在集群外进行测试</span><br><span class="hljs-comment"># 直接访问三个节点的nodeport，这时请求会被转发到pod中，不会经过ClusterIP</span><br><span class="hljs-comment"># 此时实际返回的IP要取决于被转发到的后端pod是否在当前的k8s节点上</span><br>$ curl 10.31.188.11:30088<br>10.0.1.47:6318<br>$ curl 10.31.188.11:30088<br>10.31.188.11:63944<br>$ curl 10.31.188.12:30088<br>10.31.188.12:53882<br>$ curl 10.31.188.12:30088<br>10.0.2.151:6366<br>$ curl 10.31.188.12:30088<br>10.0.2.151:6368<br>$ curl 10.31.188.12:30088<br>10.31.188.12:48174<br></code></pre></div></td></tr></table></figure>


            </div>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/categories/cloudnative/">cloudnative</a>
                    
                  </div>
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/tags/centos/">centos</a>
                    
                      <a class="hover-with-bg" href="/tags/k8s/">k8s</a>
                    
                      <a class="hover-with-bg" href="/tags/docker/">docker</a>
                    
                      <a class="hover-with-bg" href="/tags/cilium/">cilium</a>
                    
                  </div>
                
              </div>
              
              
                <div class="post-prevnext">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/20220512-k8s-05-deploy-k8s-without-kubeproxy/">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">k8s系列05-使用containerd和cilium部署kubeproxy-free的k8s集群</span>
                        <span class="visible-mobile">Previous</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/20220508-k8s-03-deploy-k8s-with-calico/">
                        <span class="hidden-mobile">k8s系列03-kubeadm部署calico网络的k8s集群</span>
                        <span class="visible-mobile">Next</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;TOC</p>
  <div class="toc-body" id="toc-body"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Search</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">keyword</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
    

    
  </main>

  <footer class="text-center mt-5 py-3">
  <div class="footer-content">
     <i class="iconfont icon-copyright"></i> <a href="https://tinychen.com/" target="_blank" rel="nofollow noopener"><span>since 2017 By TinyChen </span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Hexo-Fluid</span></a> 
  </div>
  

  
  <!-- 备案信息 -->
  <div class="beian">
    <span>
      <a href="http://beian.miit.gov.cn/" target="_blank" rel="nofollow noopener">
        粤ICP备18140640号
      </a>
    </span>
    
  </div>


  
</footer>


  <!-- SCRIPTS -->
  
  <script  src="https://cdn.jsdelivr.net/npm/nprogress@0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js" ></script>
<script  src="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>

<!-- Plugins -->


  <script  src="/js/local-search.js" ></script>



  
    <script  src="/js/img-lazyload.js" ></script>
  



  



  
    <script  src="https://cdn.jsdelivr.net/npm/tocbot@4/dist/tocbot.min.js" ></script>
  
  
    <script  src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3/dist/jquery.fancybox.min.js" ></script>
  
  
    <script  src="https://cdn.jsdelivr.net/npm/anchor-js@4/anchor.min.js" ></script>
  
  
    <script defer src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js" ></script>
  






  <script  src="https://cdn.jsdelivr.net/npm/typed.js@2/lib/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var title = document.getElementById('subtitle').title;
      
        typing(title);
      
    })(window, document);
  </script>












  
    <!-- Baidu Analytics -->
    <script defer>
      var _hmt = _hmt || [];
      (function () {
        var hm = document.createElement("script");
        hm.src = "https://hm.baidu.com/hm.js?7a96963a1145ac7fde1442d739a11ffd";
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(hm, s);
      })();
    </script>
  

  
    <!-- Google Analytics -->
    <script defer>
      window.ga = window.ga || function () { (ga.q = ga.q || []).push(arguments) };
      ga.l = +new Date;
      ga('create', 'UA-166769908-1', 'auto');
      ga('send', 'pageview');
    </script>
    <script async src='https://www.google-analytics.com/analytics.js'></script>
  

  

  

  

  





<!-- 主题的启动项 保持在最底部 -->
<script  src="/js/boot.js" ></script>


</body>
</html>
